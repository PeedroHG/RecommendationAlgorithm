# üé• Movie Recommendation Algorithm 

<details>
  <summary><b>üß≠ Sum√°rio</b></summary>
  <ol>
    <li><a href="#introducao">üìò Introdu√ß√£o</a></li>
    <li><a href="#fundamentacao">üìñ Abordagem e Fundamenta√ß√£o Te√≥rica</a></li>
    <li><a href="#datasets">üìà Datasets</a></li>
    <li><a href="metodologia">üß™ Metodologia</a></li>
    <li><a href="#estrutura">üß¨ Estrutura do Projeto</a></li>
    <li><a href="#modelagem-e-implementacao">üíª Modelagem e Implementa√ß√£o</a></li>
    <li><a href="#resultados">üìä An√°lises dos Resultados</a></li>
    <li><a href="#conclusao">‚úîÔ∏è Conclus√£o</a></li>
    <li><a href="arquivos">üìÅ Arquivos Adicionais</a></li>
    <li><a href="ambiente">üöÄ Ambiente Compila√ß√£o e Execu√ß√£o</a></li>
    <li><a href="#autores">üë• Autores</a></li>
    <li><a href="#referencias">üìö Refer√™ncias</a></li>
  </ol>
</details>

<h2 id="introducao">üìò Introdu√ß√£o</h2>

<p align="justify">
Com o r√°pido avan√ßo tecnol√≥gico e a populariza√ß√£o da internet, o volume de dados gerados diariamente cresceu exponencialmente. Essa vasta quantidade de informa√ß√£o, embora rica, apresenta um desafio significativo: como process√°-la e transform√°-la em algo √∫til e significativo para os usu√°rios?

Essa sobrecarga de informa√ß√£o pode levar a uma sensa√ß√£o de desorienta√ß√£o. Em plataformas de streaming de v√≠deo, por exemplo, a imensa disponibilidade de t√≠tulos, apesar de ser uma vantagem, pode gerar insatisfa√ß√£o, pois o usu√°rio se sente sobrecarregado com tantas op√ß√µes de escolha. Nesse contexto, os sistemas de recomenda√ß√£o surgem como uma solu√ß√£o. Eles atuam como filtros inteligentes, avaliando as informa√ß√µes dispon√≠veis sobre o hist√≥rico e os prov√°veis interesses dos usu√°rios para, ent√£o, sugerir conte√∫dos. As recomenda√ß√µes geradas por esses sistemas n√£o apenas reduzem a sobrecarga de escolha, mas tamb√©m ajudam os usu√°rios a descobrir o que √© mais relevante e adequado aos seus gostos. Assim, transformam a abund√¢ncia de dados em uma experi√™ncia personalizada e satisfat√≥ria.

Este projeto tem como objetivo desenvolver um prot√≥tipo de algoritmo de recomenda√ß√£o de filmes, baseado na an√°lise dos perfis dos usu√°rios e nas caracter√≠sticas dos itens dispon√≠veis. A abordagem adotada busca identificar padr√µes de prefer√™ncias e comportamentos para oferecer sugest√µes personalizadas, aprimorando a experi√™ncia do usu√°rio e a relev√¢ncia das recomenda√ß√µes.
</p>

<h2 id="fundamentacao">üìñ Abordagem e Fundamenta√ß√£o Te√≥rica</h2>
<p align="justify">
No contexto deste estudo, onde foi empregado o conjunto de dados <b>MovieLens 25M</b> caracterizado pelo elevado volume de registros e alta dimensionalidade, a escolha de um m√©todo eficiente para gerar recomenda√ß√µes se faz uma tarefa desafiadora, ¬†pois √© preciso conciliar escalabilidade, velocidade de processamento e qualidade preditiva diante da esparsidade e complexidade do dataset.

Algoritmos populares como k-NN tradicional ou similaridade de cosseno direta, falham em oferecer baixa escabilidade e baixa velocidade de processamento para um alto volume de dados. O primeiro falha pois, para encontrar os vizinhos mais pr√≥ximos, calcula a dist√¢ncia ou similaridade de um ponto de consulta para todos os outros pontos no conjunto de dados. Isso leva a um alto custo computacional, que cresce quadraticamente (complexidade O(n¬≤)) com o tamanho do dataset <a href="#ref1">[1]</a>, ou mais precisamente, ¬†para a tarefa mais comum de uma √∫nica consulta de predi√ß√£o, a complexidade √© descrita como O(n‚ãÖd), frequentemente simplificada para O(n) quando a dimensionalidade √© tratada como constante <a href="#ref2">[2]</a>. Para o <b>MovieLens 25M</b>, com mais de 162 mil usu√°rios e 62 mil filmes, essa abordagem se torna invi√°vel pois tanto o n√∫mero de usu√°rios quanto a dimens√£o de filmes a ser analisadas √© alto. Adicionalmente, no segundo caso, calcular a similaridade para todos os pares de itens em um grande conjunto de dados √© computacionalmente invi√°vel <a href="#ref3">[3]</a>.
Al√©m desses problemas, ¬†fatores como alta dimensionalidade (conhecida como maldi√ß√£o da alta dimensionalidade), desempenho ineficiente para matrizes espar√ßas e alto consumo de mem√≥ria tornam essas abordagens pouco atraentes <a href="#ref4">[4]</a>-<a href="#ref6">[6]</a>.

Em contraste, a t√©cnica de <b>Hashing Sens√≠vel √† Localidade (LSH) </b> se destaca como uma abordagem altamente eficiente para algoritmos de recomenda√ß√£o, superando as limita√ß√µes de m√©todos tradicionais, especialmente em contextos de grandes volumes de dados <a href="#ref7">[7]</a>,<a href="#ref8">[8]</a>. O principal objetivo da LSH ¬†√© agrupar itens de entrada semelhantes, associando-os a um mesmo hash com alta probabilidade, tamb√©m conhecido como "buckets". Diferente das t√©cnicas de hash convencionais, o LSH maximiza as colis√µes de hash em vez de minimiz√°-las <a href="#ref9">[9]</a>. Isso permite acelerar a busca por vizinhos pr√≥ximos em conjuntos de dados de alta dimensionalidade, mitigando a "maldi√ß√£o da dimensionalidade" <a href="#ref10">[10]</a>.

Quando os dados s√£o representados como vetores em um espa√ßo de alta dimens√£o, a t√©cnica de LSH mais comum utiliza hiperplanos aleat√≥rios.O objetivo aqui √© agrupar vetores que apontam em dire√ß√µes semelhantes, o que √© medido pela <b>similaridade de cosseno</b>. O processo funciona da seguinte forma:

* **Cria√ß√£o de Hiperplanos**: V√°rios hiperplanos aleat√≥rios s√£o gerados no espa√ßo vetorial. Cada hiperplano divide o espa√ßo em duas metades.
* **Gera√ß√£o do Hash**: Para cada vetor de dados, um "hash" √© gerado com base em sua posi√ß√£o em rela√ß√£o a esses hiperplanos. Para cada hiperplano, se o vetor estiver de um lado, ele recebe um bit '1', e se estiver do outro lado, recebe um bit '0'.
* **C√≥digo de Hash**: Ao combinar os bits de todos os hiperplanos, cada vetor recebe um c√≥digo de hash bin√°rio (uma sequ√™ncia de 0s e 1s). Vetores que est√£o pr√≥ximos no espa√ßo angular (alta similaridade de cosseno) t√™m uma alta probabilidade de cair do mesmo lado de muitos dos hiperplanos aleat√≥rios, resultando em c√≥digos de hash id√™nticos ou muito semelhantes.

No contexto de LSH, esse c√≥digo de hash bin√°rio serve como a chave para o bucket. A cria√ß√£o desses buckets de candidatos √© a raz√£o fundamental pela qual o LSH consegue mitigar a "maldi√ß√£o da dimensionalidade". A pergunta crucial que surge dessa abordagem √©: qual √© o verdadeiro ganho de desempenho e quais s√£o os custos associados a essa aproxima√ß√£o?

Em contraste com uma busca por for√ßa bruta (k-NN), cujo custo computacional cresce de forma linear ou quadr√°tica com o volume de dados (O(nd) ou O(n¬≤)) e se torna rapidamente proibitivo, o LSH direciona a busca apenas para um pequeno subconjunto de itens promissores. Ao consultar apenas os candidatos que colidem no mesmo bucket, o tempo de busca √© drasticamente reduzido para uma complexidade sublinear, representando o seu principal ganho. Contudo, essa efici√™ncia n√£o √© gratuita e seu custo mais significativo reside na pr√≥pria aproxima√ß√£o. O LSH aceita a possibilidade de erros, que se manifestam como falsos negativos, onde um vizinho real √© perdido por n√£o colidir em nenhum bucket, e falsos positivos, onde itens n√£o similares colidem por acaso, exigindo verifica√ß√µes de dist√¢ncia desnecess√°rias que consomem tempo. A gest√£o desses erros constitui um segundo custo, o de engenharia, pois exige um ajuste fino dos par√¢metros do algoritmo ‚Äî como o n√∫mero de tabelas de hash (L) e de fun√ß√µes por tabela (k) ‚Äî para encontrar o balan√ßo ideal entre a precis√£o dos resultados e a velocidade da consulta. Por fim, h√° o custo inicial de pr√©-processamento e mem√≥ria, um investimento de tempo e recursos computacionais necess√°rio para construir e armazenar as tabelas de hash antes que qualquer busca possa ser realizada.

A proposta desenvolvida neste estudo √¢ncora-se na ideia simplista do k-NN e as vantagens da abordagem LSH. Para evitar essa busca exaustiva, o sistema utiliza LSH como um poderoso filtro inteligente na primeira etapa. Cada usu√°rio, representado por seu perfil de avalia√ß√µes de filmes, √© mapeado para buckets LSH, que funcionam como "vizinhan√ßas" de gostos, agrupando usu√°rios com perfis de avalia√ß√£o parecidos. Assim, quando √© necess√°rio encontrar os vizinhos mais pr√≥ximos de um usu√°rio, o sistema n√£o varre todo o banco de dados. Em vez disso, ele usa o LSH para filtrar rapidamente um conjunto reduzido de candidatos promissores ‚Äî aqueles que ca√≠ram nos mesmos buckets que o usu√°rio-alvo. S√≥ ent√£o, dentro desse conjunto pr√©-filtrado e muito menor, √© aplicado o c√°lculo de similaridade cosseno (k-NN) para selecionar os k vizinhos mais pr√≥ximos e, finalmente, gerar as recomenda√ß√µes.

Dessa forma, o sistema combina o melhor dos dois mundos: a velocidade da busca aproximada do LSH para identificar um conjunto relevante de usu√°rios e a precis√£o da m√©trica de similaridade do k-NN para fazer a escolha final dentro do bucket. Esta abordagem em duas etapas resolve diretamente a quest√£o da escalabilidade, permitindo que recomenda√ß√µes personalizadas sejam geradas de maneira eficiente, mesmo em um ecossistema com um n√∫mero massivo de usu√°rios e itens.

Ao gerar as recomenda√ß√µes √© necess√°rio avaliar a qualidade das sugest√µes de filmes sugeridas pelo algoritmo. Em nossa abordagem de recomenda√ß√£o, cada filme candidato recebe um grau de prefer√™ncia calculado a partir das avalia√ß√µes de usu√°rios semelhantes, de modo que os vizinhos com perfis mais pr√≥ximos exercem maior influ√™ncia. Para isso, combinamos cada avalia√ß√£o com o grau de similaridade do usu√°rio que a fez e, em seguida, normalizamos pelo total de similaridade acumulada, garantindo que opini√µes mais alinhadas pesem mais no resultado final. Essa estimativa √© ent√£o convertida para uma escala percentual, refletindo o n√≠vel de confiabilidade da recomenda√ß√£o. Por fim, apresentamos ao usu√°rio apenas os t√≠tulos que ele ainda n√£o viu, ordenados pelo valor percentual, de modo a destacar primeiro as op√ß√µes com maior chance de agradar o usu√°rio-alvo. </p>

<h2 id="datasets"> üìä Datasets</h2>

O conjunto de dados utilizado no sistema de recomenda√ß√£o √© o **MovieLens 25M**, dispon√≠vel na plataforma Kaggle [`ml-25m`](https://www.kaggle.com/datasets/patriciabrezeanu/movielens-full-25-million-recommendation-data). Ele cont√©m registros de classifica√ß√£o de filmes por estrelas, al√©m de marca√ß√µes com texto livre realizadas na plataforma oficial [MovieLens](http://movielens.org), um renomado servi√ßo de recomenda√ß√£o de filmes.

O conjunto de dados possui as seguintes caracter√≠sticas:

-   **Total de avalia√ß√µes:** 25.000.095 classifica√ß√µes
-   **Total de marca√ß√µes (tags):** 1.093.360 tags aplicadas
-   **Quantidade de filmes:** 62.423 filmes inclu√≠dos
-   **Per√≠odo de coleta:** 9 de janeiro de 1995 a 21 de novembro de 2019
-   **Usu√°rios:** 162.541 usu√°rios selecionados aleatoriamente

Para alimentar o sistema de recomenda√ß√£o, os dados utilizados foram especificamente os arquivos `movies.csv` e `ratings.csv`.

Em rela√ß√£o aos usu√°rios e √† estrutura dos dados:
-   Todos os usu√°rios selecionados avaliaram pelo menos **20 filmes**.
-   Todos os arquivos do conjunto de dados s√£o formatados em `.csv`, contendo uma √∫nica linha de cabe√ßalho.
-   Colunas que cont√™m v√≠rgulas (`,`) s√£o escapadas utilizando **aspas duplas** (`"`).
-   Os arquivos s√£o codificados em **UTF-8**.

### Estrutura dos Arquivos Usados

#### `ratings.csv`
Este arquivo cont√©m todas as avalia√ß√µes dos usu√°rios. Cada linha, ap√≥s o cabe√ßalho, representa uma **avalia√ß√£o de um filme por um usu√°rio**, no seguinte formato:

```csv
userId,movieId,rating,timestamp
```

#### `movies.csv`
Este arquivo cont√©m informa√ß√µes sobre os filmes presentes no conjunto de dados MovieLens 25M. Cada linha, ap√≥s o cabe√ßalho, representa um filme e segue o seguinte formato:

```csv
movieId,title,genres
```

<h2 id="metodologia"> üß™ Metodologia</h2>

A constru√ß√£o do algoritmo de recomenda√ß√£o ancorou-se nas t√©cnicas k-NN e LSH discutidas nas se√ß√µes anteriores. Para tal fim, foram desenvolvidas 3 etapas, enumeradas da seguinte maneira:

1. **Pr√©-processamento**: adotou-se um protocolo de sele√ß√£o de usu√°rios com pelo menos 50 avalia√ß√µes distintas e de filmes avaliados por no m√≠nimo 50 usu√°rios, garantindo representatividade estat√≠stica e reduzindo ru√≠dos provenientes de intera√ß√µes esparsas; em seguida, eliminaram-se registros duplicados e entradas inconsistentes ‚Äî incluindo linhas com valores ausentes ou ratings fora do intervalo permitido ‚Äî para assegurar a integridade dos dados.
2. **Constru√ß√£o do modelo**:
Ap√≥s o pr√©-processamento, os dados filtrados s√£o convertidos em uma matriz usu√°rio-item, estrutura fundamental para opera√ß√µes de similaridade e recomenda√ß√£o. Cada linha representa um usu√°rio e cada coluna um filme, com os valores correspondendo √†s avalia√ß√µes atribu√≠das.
Em seguida, s√£o calculadas as normas dos vetores de cada usu√°rio, etapa essencial para o c√°lculo eficiente da similaridade cosseno.
O modelo LSH (Locality-Sensitive Hashing) √© ent√£o constru√≠do:
Gera-se um conjunto de hiperplanos aleat√≥rios para cada tabela LSH, projetando os vetores dos usu√°rios em m√∫ltiplas tabelas hash, o que permite agrupar usu√°rios similares em buckets comuns.
Essa estrutura possibilita a busca aproximada de vizinhos mais pr√≥ximos (k-NN) de forma eficiente, mesmo em grandes volumes de dados, reduzindo drasticamente o custo computacional em rela√ß√£o √† busca exaustiva.
3. **Gera√ß√£o das recomenda√ß√µes**:
Para cada usu√°rio-alvo, o sistema utiliza o LSH para identificar rapidamente um conjunto de vizinhos mais pr√≥ximos (usu√°rios similares).
A partir desses vizinhos, calcula-se um score de recomenda√ß√£o para cada filme n√£o avaliado pelo usu√°rio, ponderando as avalia√ß√µes dos vizinhos pela similaridade e aplicando filtros adicionais, como limiar m√≠nimo de similaridade e compara√ß√£o com a m√©dia do usu√°rio.
Caso n√£o haja recomenda√ß√µes principais, um mecanismo de fallback sugere filmes com alguma similaridade residual.
As recomenda√ß√µes finais s√£o ordenadas pelo score percentual e apresentadas ao usu√°rio, juntamente com o t√≠tulo do filme e o grau de recomenda√ß√£o, permitindo uma avalia√ß√£o clara e interpret√°vel dos resultados.

Para avaliar a qualidade da recomenda√ß√£o, o sistema utiliza o score de recomenda√ß√£o atribu√≠do a cada filme para o usu√°rio-alvo. Esse score √© calculado com base na m√©dia ponderada das avalia√ß√µes dos vizinhos mais similares, considerando apenas aqueles cuja similaridade ultrapassa um limiar definido. O score reflete o grau de confian√ßa do sistema de que o usu√°rio ir√° apreciar o filme sugerido. A fim de tornar essa avalia√ß√£o mais intuitiva, o score √© convertido para uma escala percentual de 0 a 100%.

<h2 id="estrutura"> üß¨ Estrutura do Projeto</h2>

```text
üìÅ projeto/
‚îú‚îÄ‚îÄ üìÇ datasets/          # Arquivos de entrada
‚îú‚îÄ‚îÄ üìÇ src/               # C√≥digos principais
‚îú‚îÄ‚îÄ üìÇ outcome/           # Arquivos de sa√≠da
‚îú‚îÄ‚îÄ üìÇ include/           # Arquivos de cabe√ßalho
‚îú‚îÄ‚îÄ README.md
```

<h2 id="modelagem-e-implementacao"> üíª Modelagem e Implementa√ß√£o</h2>

A escolha do C++ para a implementa√ß√£o do sistema de recomenda√ß√£o de filmes foi motivada pela sua capacidade de oferecer controle de baixo n√≠vel e elevado desempenho computacional, caracter√≠sticas cruciais para processar eficazmente grandes volumes de dados. Esta robustez √© complementada pela utiliza√ß√£o estrat√©gica de estruturas de dados otimizadas da Standard Template Library (STL) e pela paraleliza√ß√£o intensiva via OpenMP, visando a maximiza√ß√£o da efici√™ncia e a escalabilidade do processamento, especialmente cr√≠tica para o manejo de datasets volumosos. A arquitetura adotada para o projeto √© intrinsecamente modular, concebida para promover a clareza, a manutenibilidade e a extensibilidade. Esta organiza√ß√£o l√≥gica compreende um pipeline integral que se estende desde o processamento inicial e a curadoria dos dados at√© a fase final de gera√ß√£o de recomenda√ß√µes e a rigorosa avalia√ß√£o do modelo. Para garantir uma execu√ß√£o sequencial e l√≥gica, esses componentes foram articulados em fases distintas, a saber:

* ‚öôÔ∏è **Fase 1:** <a href="#fase1-dados">Carregamento e Pr√©-processamento de Dados</a>
* üèóÔ∏è **Fase 2:** <a href="#fase2-modelo">Constru√ß√£o de Componentes do Modelo Central</a>
* ‚ö° **Fase 2.5:** <a href="#fase2_5-lsh">Constru√ß√£o do Modelo LSH</a>
* üí° **Fase 3:** <a href="#fase3-recomendacoes">Gera√ß√£o de Recomenda√ß√µes LSH</a>
* üìä **M√≥dulo de Avalia√ß√£o:** <a href="#modulo-avaliacao">Avalia√ß√£o do Modelo</a>

### Defini√ß√£o de Tipos de Dados

Para promover a clareza, a legibilidade e a manuten√ß√£o do c√≥digo-fonte, o projeto faz uso extensivo de **alias de tipos (type aliases)**. Essas defini√ß√µes, centralizadas no [arquivo `types.hpp`](src/types.hpp), padronizam as estruturas de dados complexas e conferem maior expressividade aos nomes das vari√°veis e par√¢metros, refletindo seu prop√≥sito dentro do algoritmo. O detalhamento de cada tipo ser√° apresentado contextualmente ao longo da descri√ß√£o das fases de implementa√ß√£o, no momento de sua primeira utiliza√ß√£o relevante.

<h3 id="fase1-dados">‚öôÔ∏è Fase 1: Carregamento e Pr√©-processamento de Dados</h3>

<p align="justify">
A fase inicial do sistema √© dedicada √† ingest√£o e √† filtragem do dataset. O processo √© projetado para transformar os dados brutos em um conjunto de informa√ß√µes estruturado, denso e de alta qualidade, otimizado para as etapas subsequentes de modelagem e recomenda√ß√£o. Para isso, adota-se um pipeline de I/O e transforma√ß√£o de dados de alta performance.
</p>

<ol>
  <li>
    <p align="justify">
      <strong>Estrat√©gia de Leitura e Parsing de Alta Performance</strong>
    </p>
    <p align="justify">
      Para mitigar o gargalo de desempenho associado √† leitura de arquivos massivos e garantir a m√°xima efici√™ncia na extra√ß√£o dos dados, uma estrat√©gia de I/O otimizada com <strong>memory-mapped files (mmap)</strong> √© implementada na fun√ß√£o <code>readRatingsCSV</code>.
    </p>
    <ul>
      <li><strong>Leitura com <code>mmap</code>:</strong> Em vez de ler o arquivo <code>ratings.csv</code> em blocos com `ifstream`, o sistema utiliza `mmap` para mapear o arquivo diretamente na mem√≥ria virtual do processo. Isso elimina c√≥pias de dados entre o kernel e o espa√ßo do usu√°rio, sendo uma das formas mais r√°pidas de ler arquivos grandes em sistemas POSIX. O arquivo se comporta como um grande array de bytes na mem√≥ria, permitindo acesso e processamento direto.</li>
      <li><strong>Parsing Paralelo e Eficiente:</strong> O conte√∫do mapeado √© ent√£o dividido em "chunks" (peda√ßos) que s√£o distribu√≠dos entre m√∫ltiplas threads usando OpenMP (<code>#pragma omp parallel</code>). Cada thread analisa as linhas de seu chunk de forma independente, utilizando ferramentas modernas de C++ para m√°xima performance: <code>std::string_view</code> para evitar a cria√ß√£o de novas strings e <code>std::from_chars</code> para convers√µes num√©ricas r√°pidas e sem aloca√ß√£o de mem√≥ria.</li>
      <li><strong>Armazenamento sem Concorr√™ncia:</strong> Para evitar condi√ß√µes de corrida (race conditions) durante a inser√ß√£o paralela, cada thread armazena os dados que processou em um log de avalia√ß√µes local (<code>thread_local_logs</code>). Ao final da fase paralela, esses logs locais s√£o combinados sequencialmente no mapa principal, uma opera√ß√£o r√°pida que consolida os resultados.</li>
    </ul>
  </li>
  <li>
    <p align="justify">
      <strong>Crit√©rios de Filtragem do Dataset</strong>
    </p>
    <p align="justify">
      O prop√≥sito da filtragem √© aumentar a densidade e a confiabilidade do conjunto de dados, um passo fundamental para a efic√°cia de algoritmos de filtragem colaborativa. O sistema aplica um limiar m√≠nimo de relev√¢ncia (<code>MIN_RATINGS_PER_ENTITY</code>) em um processo paralelizado de m√∫ltiplas etapas.
    </p>
    <ul>
      <li><strong>Contagem Paralela e <i>Lock-Free</i>:</strong> A fun√ß√£o <code>countEntityRatings</code> contabiliza o n√∫mero de avalia√ß√µes por usu√°rio e por filme. Para otimizar essa contagem, ela √© paralelizada de forma a evitar o uso de locks (que serializariam o acesso): cada thread escreve as contagens de filmes em seu pr√≥prio mapa local. Ap√≥s a conclus√£o, esses mapas locais s√£o agregados no mapa global.</li>
      <li><strong>Identifica√ß√£o e Aplica√ß√£o do Filtro:</strong> A fun√ß√£o <code>identifyValidEntities</code> armazena os IDs das entidades que atendem ao limiar em um <code>std::unordered_set</code>, que permite consultas de valida√ß√£o com complexidade de tempo m√©dia de O(1). Em seguida, <code>filterUserRatingsLog</code> aplica esse filtro, tamb√©m de forma paralela, onde cada thread processa um subconjunto de usu√°rios, mantendo apenas as avalia√ß√µes de filmes v√°lidos.</li>
    </ul>
  </li>
  <li>
    <p align="justify">
      <strong>Gera√ß√£o dos Artefatos de Sa√≠da com Paraleliza√ß√£o OpenMP</strong>
    </p>
    <p align="justify">
      Ao final do processo, os dados refinados s√£o serializados e persistidos em arquivos que servir√£o de base para as fases seguintes. A escrita desses arquivos √© otimizada com paralelismo.
    </p>
    <ul>
      <li><strong>Dataset Filtrado:</strong> A fun√ß√£o <code>writeFilteredRatingsToFile</code> escreve os dados refinados no arquivo <code>filtered_dataset.dat</code>. A gera√ß√£o das strings de sa√≠da √© feita em paralelo: cada thread formata as linhas para um subconjunto de usu√°rios e as armazena em um vetor de strings. Ao final, todas as linhas s√£o concatenadas em uma √∫nica string gigante, que √© escrita no arquivo com uma √∫nica chamada de I/O, minimizando o acesso ao disco.</li>
      <li><strong>Gera√ß√£o de Amostra para Explora√ß√£o:</strong> A fun√ß√£o <code>writeRandomUserIdsToExplore</code> seleciona uma amostra aleat√≥ria de usu√°rios e salva seus IDs no arquivo <code>explore.dat</code>. Crucialmente, ela utiliza um gerador de n√∫meros aleat√≥rios com uma semente fixa (<code>std::mt19937 generator(42)</code>). Isso garante que a sele√ß√£o de usu√°rios seja sempre a mesma a cada execu√ß√£o do programa, o que √© vital para a <strong>reprodutibilidade</strong> dos experimentos e an√°lises.</li>
    </ul>
  </li>
  <li>
    <p align="justify">
      <strong>An√°lise Conceitual das Estruturas e Fun√ß√µes Chave</strong>
    </p>
    <p align="justify">
      A alta performance desta fase √© resultado direto da escolha criteriosa de estruturas de dados e fun√ß√µes. Abaixo, detalhamos o porqu√™ de cada escolha em compara√ß√£o com suas alternativas.
    </p>
    <ul>
      <li>
        <strong><code>mmap</code> vs. <code>std::ifstream</code></strong>
        <ul>
          <li><strong>Conceito (<code>mmap</code>):</strong> Mapeia um arquivo diretamente no espa√ßo de endere√ßo virtual, tratando-o como um array na mem√≥ria. Isso elimina a sobrecarga de copiar dados entre o buffer do kernel e o do aplicativo, tornando-o ideal para leituras de arquivos muito grandes.</li>
          <li><strong>Justificativa:</strong> Para o dataset de 25 milh√µes de avalia√ß√µes, `mmap` √© significativamente mais r√°pido do que a leitura tradicional com `std::ifstream`, pois minimiza as chamadas de sistema e as c√≥pias de dados.</li>
        </ul>
      </li>
      <li>
        <strong><code>std::unordered_map</code> vs. <code>std::map</code></strong>
        <ul>
          <li><strong>Conceito (<code>unordered_map</code>):</strong> √â uma tabela de hash que oferece acesso, inser√ß√£o e remo√ß√£o em tempo m√©dio <strong>constante, O(1)</strong>.</li>
          <li><strong>Justificativa:</strong> Para agrupar e contar avalia√ß√µes por ID, a velocidade de acesso √© a prioridade. Como a ordem dos IDs n√£o √© importante para esta tarefa, a complexidade O(1) do `std::unordered_map` √© superior √† O(log n) do `std::map` (uma √°rvore bin√°ria balanceada).</li>
        </ul>
      </li>
      <li>
        <strong><code>std::unordered_set</code> vs. <code>std::vector</code></strong>
        <ul>
          <li><strong>Conceito (<code>unordered_set</code>):</strong> Uma tabela de hash que armazena elementos √∫nicos. Sua principal for√ßa √© verificar a exist√™ncia de um elemento em tempo m√©dio <strong>constante, O(1)</strong>.</li>
          <li><strong>Justificativa:</strong> Na etapa de filtragem, a opera√ß√£o mais comum √© verificar se um ID de usu√°rio ou filme √© "v√°lido". O `std::unordered_set` responde a essa pergunta em tempo O(1), sendo a escolha mais r√°pida. Uma busca em um `std::vector` seria linear (O(n)), o que seria proibitivamente lento.</li>
        </ul>
      </li>
      <li>
        <strong><code>std::string_view</code> vs. <code>std::string</code></strong>
        <ul>
          <li><strong>Conceito (<code>string_view</code>):</strong> √â um objeto "n√£o-propriet√°rio" que aponta para uma sequ√™ncia de caracteres existente sem criar c√≥pias.</li>
          <li><strong>Justificativa:</strong> Ao processar milh√µes de linhas de um arquivo CSV, o uso de `std::string_view` para o parsing evita milh√µes de aloca√ß√µes de mem√≥ria que ocorreriam ao criar substrings com `std::string`, resultando em um ganho de performance massivo.</li>
        </ul>
      </li>
        <li>
        <strong><code>std::from_chars</code> vs. <code>std::stoi/stof</code></strong>
        <ul>
          <li><strong>Conceito (<code>std::from_chars</code>):</strong> Uma fun√ß√£o de convers√£o de baixo n√≠vel que n√£o aloca mem√≥ria e n√£o lan√ßa exce√ß√µes, tornando-a mais r√°pida e previs√≠vel.</li>
          <li><strong>Justificativa:</strong> √â a ferramenta ideal para um parser de alta performance, pois converte os dados num√©ricos de forma eficiente e sem a sobrecarga do tratamento de exce√ß√µes ou depend√™ncia de localidade, comuns em `stoi` ou `stof`.</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>


<h3 id="fase2-modelo">üèóÔ∏è Fase 2: Constru√ß√£o de Componentes do Modelo Central</h3>

A Fase 2 do processo de implementa√ß√£o concentra-se na transforma√ß√£o dos dados de avalia√ß√µes pr√©-processados em estruturas otimizadas, essenciais para os c√°lculos de similaridade subjacentes ao algoritmo de recomenda√ß√£o. Este conjunto de opera√ß√µes √© implementado no m√≥dulo `recommender_engine.cpp/.hpp`.

Os principais processos realizados nesta fase s√£o:

1.  **Mapeamento de Avalia√ß√µes para Matriz Esparsa de Usu√°rio-Item:**
    * Esta fun√ß√£o √© respons√°vel por converter o formato inicial de log de avalia√ß√µes, representado por `UserRatingsLog` (um `std::unordered_map` onde cada `UserID` √© mapeado a um `std::vector` de pares `(MovieID, Rating)`), em uma `UserItemMatrix`. A `UserItemMatrix` √© uma estrutura `std::unordered_map<int, std::unordered_map<int, float>>`, que, de forma qualitativa, age como uma representa√ß√£o esparsa da matriz de avalia√ß√µes. Sua escolha √© estrat√©gica para **otimiza√ß√£o de acesso**: ao aninhar `unordered_maps`, o sistema permite que, dado um `UserID` e um `MovieID`, a avalia√ß√£o correspondente seja acessada diretamente com complexidade m√©dia de tempo constante ($O(1)$). Isso √© fundamental para a efici√™ncia em opera√ß√µes futuras, como o c√°lculo do produto escalar na similaridade de cosseno, onde a busca por avalia√ß√µes espec√≠ficas √© frequente e a esparsidade dos dados evita a aloca√ß√£o desnecess√°ria de mem√≥ria para filmes n√£o avaliados.

2.  **Pr√©-c√°lculo e Armazenamento das Normas de Usu√°rios**
    * A `computeUserNorms` calcula a norma Euclidiana  para o vetor de avalia√ß√µes de cada usu√°rio presente na rec√©m-constru√≠da `UserItemMatrix`. As normas s√£o ent√£o armazenadas na estrutura `UserNormsMap`, que √© um `std::unordered_map<int, float>`. O **foco principal na otimiza√ß√£o** aqui reside no **pr√©-c√°lculo e armazenamento dessas magnitudes**. A similaridade de cosseno, m√©trica central para determinar a semelhan√ßa entre usu√°rios, exige a divis√£o pelo produto das normas dos vetores comparados. Ao ter as normas j√° computadas e acess√≠veis em $O(1)$, o sistema evita a repeti√ß√£o de um c√°lculo de raiz quadrada e somas para cada par de usu√°rios durante as milh√µes de compara√ß√µes de similaridade que ocorrem nas fases de busca por vizinhos. Este processo √© adicionalmente **paralelizado utilizando OpenMP**, o que distribui a carga computacional de c√°lculo de normas entre m√∫ltiplos n√∫cleos de processamento, acelerando significativamente a prepara√ß√£o dos dados para a fase LSH em grandes datasets.

Ao final desta fase, o sistema possui a `UserItemMatrix` e a `UserNormsMap` totalmente constru√≠das, representando os perfis de usu√°rios em um formato otimizado para as opera√ß√µes de hashing sens√≠vel √† localidade e busca por vizinhos.

<h3 id="fase2_5-lsh">‚ö° Fase 2.5: Constru√ß√£o do Modelo LSH</h3>

A constru√ß√£o de um modelo de Locality-Sensitive Hashing (LSH) mapeia dados de alta dimens√£o para agrupar itens semelhantes em "buckets", preservando suas rela√ß√µes geom√©tricas. No caso da similaridade de cosseno, a LSH utiliza hiperplanos aleat√≥rios para converter vetores de dados em assinaturas bin√°rias. Dessa forma, pontos com orienta√ß√£o similar no espa√ßo original acabam no mesmo bucket, o que otimiza a busca por vizinhos pr√≥ximos.

O processo consiste em quatro etapas essenciais e interligadas:

1.  **Vetoriza√ß√£o dos Dados:** Converter cada item do dataset em um vetor num√©rico de alta dimensionalidade.
2.  **Indexa√ß√£o com Fun√ß√µes Hash:** Gerar uma assinatura hash para cada vetor usando um conjunto de fun√ß√µes LSH (neste caso, hiperplanos aleat√≥rios). Essa assinatura determina o bucket onde o item ser√° armazenado.
3.  **Amplifica√ß√£o com M√∫ltiplas Tabelas:** Utilizar v√°rias tabelas de hash independentes para aumentar a probabilidade de que itens verdadeiramente similares colidam em ao menos uma delas, reduzindo a chance de falsos negativos.
4.  **Recupera√ß√£o e Refinamento:** Para uma consulta, primeiro coletar um conjunto de candidatos dos buckets correspondentes nas tabelas e, em seguida, aplicar a m√©trica de similaridade exata (e mais custosa) apenas a esse grupo reduzido para encontrar os vizinhos mais pr√≥ximos.

**Vetoriza√ß√£o dos Dados:**
* A primeira etapa para a constru√ß√£o da LSH reside na vetoriza√ß√£o e normaliza√ß√£o do espa√ßo de caracter√≠sticas. Para tal fim, √© necess√°rio inicialmente mapear a dimens√£o do dataset. A dimens√£o √© baseada no n√∫mero de filmes √∫nicos. Essa escolha se deve ao fato de o n√∫mero de filmes ser menor que o n√∫mero de usu√°rios, reduzindo dessa forma a dimensionalidade do problema. Os `movieIds` originais, que s√£o esparsos e n√£o sequenciais, s√£o mapeados para um vetor de √≠ndices densos. Essa etapa √© crucial para criar uma representa√ß√£o vetorial consistente para cada usu√°rio.

    O funcionamento dessa parte consiste em percorrer todos os usu√°rios e todos os filmes avaliados, coletando todos os IDs √∫nicos de filmes presentes na matriz usu√°rio-item. Cada filme recebe um √≠ndice sequencial (0, 1, 2, ...), criando um mapeamento de ID real para √≠ndice denso. Posteriormente, a vari√°vel `dimensionality` armazena o n√∫mero total de filmes √∫nicos, que ser√° a dimens√£o dos vetores e dos hiperplanos usados no LSH. O c√≥digo tamb√©m faz uma checagem de seguran√ßa: se a dimensionalidade for zero, mas a matriz n√£o estiver vazia, emite um erro.

    A escolha da estrutura <code>std::set</code> reside na natureza intr√≠nseca da estrutura que funciona como um container que armazena elementos sem duplicatas e de forma ordenada, permitindo inser√ß√£o e busca eficientes; assim, ao percorrer todos os filmes avaliados por todos os usu√°rios e inseri-los no set, o c√≥digo assegura que cada filme ser√° contado apenas uma vez, facilitando o c√°lculo da dimensionalidade do espa√ßo de itens e o mapeamento para √≠ndices densos, etapas essenciais para a constru√ß√£o eficiente do modelo LSH.

**Indexa√ß√£o com Fun√ß√µes Hash**
* A segunda etapa, consiste na cria√ß√£o das fun√ß√µes hash. Neste projeto, a fam√≠lia de fun√ß√µes de hash para a similaridade de cosseno √© baseada em proje√ß√µes aleat√≥rias (hiperplanos). Para uma arquitetura LSH com $L$ tabelas de hash e $K$ fun√ß√µes de hash por tabela, s√£o gerados $L\cdot K$ vetores de hiperplanos, {$h_1,h_2,...,h_{L*K}$, onde cada $h\in R^D$. Os componentes de cada vetor $h$ s√£o amostrados independentemente de uma distribui√ß√£o est√°vel, tipicamente a Normal Padr√£o, $N(0,1)$, para garantir isotropia (n√£o h√° dire√ß√£o privilegiada), parti√ß√µes balanceadas (50% de chance em cada lado) e invari√¢ncia rotacional.

    O conjunto de hiperplanos aleat√≥rios para a tabela LSH de √≠ndices $i$ √© constru√≠do pela fun√ß√£o `generateSingleHyperplaneSet`.

    Cada hiperplano √© um vetor de n√∫meros aleat√≥rios com dimens√£o igual ao n√∫mero de filmes √∫nicos, e o conjunto de hiperplanos define como os usu√°rios ser√£o "hashados" (projetados) no espa√ßo LSH. A diversidade dos hiperplanos determinam a capacidade do LSH de agrupar usu√°rios similares nos mesmos buckets, tornando a busca por vizinhos eficientes e relevantes. Sem essa gera√ß√£o de hiperplanos aleat√≥rios, o LSH n√£o funcionaria corretamente, pois n√£o haveria uma maneira eficiente de dividir o espa√ßo de usu√°rios em regi√µes de similaridade.

    ```cpp
    HyperplaneSet generateSingleHyperplaneSet(int num_hyperplanes, int dimensionality, std::mt19937& rng) {
        HyperplaneSet hyperplane_set;
        hyperplane_set.reserve(num_hyperplanes);
        std::normal_distribution`<float>` distribution(0.0, 1.0); // Distribui√ß√£o normal padr√£o

        for (int i = 0; i < num_hyperplanes; ++i) {
            Hyperplane plane(dimensionality);
            for (int j = 0; j < dimensionality; ++j) {
                plane[j] = distribution(rng);
            }
            hyperplane_set.push_back(plane);
        }
        return hyperplane_set;
    }
    ```


**Amplifica√ß√£o com M√∫ltiplas Tabelas:**

* A terceira etapa, reside na implementa√ß√£o do c√°lculo do hash LSH para um usu√°rio, usando o conjunto de hiperplanos. O objetivo √© transformar o vetor de avalia√ß√µes do usu√°rio em um valor bin√°rio (hash) que representa em que lado de cada hiperplano o usu√°rio est√°, agrupando usu√°rios similares em buckets. O processo de hashing consiste em

* Para cada hiperplano do conjunto:
  * Calcula o produto escalar entre o vetor de avalia√ß√µes do usu√°rio e o vetor do hiperplano.
  * Isso significa multiplicar cada nota dada pelo usu√°rio pelo peso correspondente do hiperplano (associado ao filme), somando tudo.
  * Se o resultado do produto escalar for maior ou igual a zero, o bit correspondente do hash √© ativado (colocado como 1).
  * Caso contr√°rio, o bit permanece 0.
  * Cada hiperplano define um "lado" do espa√ßo: o hash indica de que lado do hiperplano o usu√°rio est√°.

    ```cpp
    LSHHashValue computeLSHHash(const std::unordered_map<int, float>& user_ratings,
                                const HyperplaneSet& hyperplane_set,
                                const MovieIdToDenseIdxMap& movie_to_idx) {
        LSHHashValue hash = 0;
        if (hyperplane_set.empty()) return hash; // Nenhum hiperplano, hash 0

        // Verifica se NUM_HYPERPLANES_PER_TABLE (tamanho de hyperplane_set) excede os bits de LSHHashValue
        if (hyperplane_set.size() > sizeof(LSHHashValue) * 8) {
            std::cerr << "Error: Number of hyperplanes exceeds bits in LSHHashValue type!" << std::endl;
            // Lida com o erro, talvez truncando ou usando um tipo de hash maior se necess√°rio.
            // Por agora, vamos prosseguir, mas isso √© uma verifica√ß√£o importante.
        }

        for (size_t i = 0; i < hyperplane_set.size(); ++i) {
            const auto& plane = hyperplane_set[i];
            float dot_product = 0.0f;
            for (const auto& rating_entry : user_ratings) {
                int movie_id = rating_entry.first;
                float rating = rating_entry.second;
                auto it_idx = movie_to_idx.find(movie_id);
                if (it_idx != movie_to_idx.end()) {
                    int dense_idx = it_idx->second;
                    if (dense_idx < static_cast`<int>`(plane.size())) {
                        dot_product += rating * plane[dense_idx];
                    }
                }
            }
            if (dot_product >= 0) {
                hash |= (1ULL << i);
            }
        }
        return hash;
    ```

    Ao final, o hash √© um n√∫mero inteiro, onde cada bit representa a posi√ß√£o do usu√°rio em rela√ß√£o a um hiperplano. Usu√°rios com perfis parecidos tendem a ter hashes parecidos, caindo nos mesmos "baldes" (buckets) do LSH.

**Recupera√ß√£o e Refinamento**

*    A quarta etapa consiste finalmente na constru√ß√£o das tabelas hash utilizando a fun√ß√£o <code>buildLSHTables</code>. O objetivo principal dessa fun√ß√£o √© organizar os usu√°rios em grupos (buckets) de acordo com a similaridade de seus perfis, de forma eficiente e escal√°vel.

     O processo come√ßa convertendo a matriz de avalia√ß√µes dos usu√°rios em um vetor, facilitando o processamento paralelo. Para cada conjunto de hiperplanos (cada tabela LSH), a fun√ß√£o percorre todos os usu√°rios e calcula, para cada um, um hash LSH. Esse hash √© obtido projetando o vetor de avalia√ß√µes do usu√°rio nos hiperplanos e verificando, para cada hiperplano, de que lado o usu√°rio est√°. O resultado √© um valor bin√°rio que serve como chave para o bucket onde o usu√°rio ser√° inserido.

     A constru√ß√£o das tabelas √© feita de forma paralela: cada thread calcula os hashes de um subconjunto de usu√°rios e armazena temporariamente os resultados. Depois, em uma etapa sequencial, todos os usu√°rios s√£o inseridos nos buckets correspondentes de cada tabela LSH. Isso garante efici√™ncia mesmo em bases de dados grandes, aproveitando o poder de processamento de m√∫ltiplos n√∫cleos.

     O resultado final √© um conjunto de tabelas onde cada bucket cont√©m os IDs dos usu√°rios que compartilham o mesmo hash LSH para aquele conjunto de hiperplanos. Assim, quando o sistema precisa encontrar usu√°rios similares a um alvo, ele pode buscar apenas nos buckets correspondentes, reduzindo drasticamente o n√∫mero de compara√ß√µes necess√°rias.

<h3 id="fase3-recomendacoes">üí° Fase 3: Gera√ß√£o de Recomenda√ß√µes LSH</h3>

<p align="justify">
  Esta √© a fase mais importante do sistema, onde o modelo Locality-Sensitive Hashing (LSH), constru√≠do na etapa anterior, √© efetivamente utilizado para gerar recomenda√ß√µes de filmes. O processo √© desenhado para ser escal√°vel e perform√°tico, processando um conjunto de usu√°rios-alvo em paralelo para gerar um arquivo de sa√≠da com as Top-N recomenda√ß√µes para cada um.
</p>

<ol>
  <li>
    <p align="justify"><strong>Carregamento dos Usu√°rios-Alvo e Prepara√ß√£o</strong></p>
    <ul>
      <li><p align="justify">O processo inicia com a leitura do arquivo <code>explore.dat</code> atrav√©s da fun√ß√£o <code>loadExploreUserIds</code>. Este arquivo cont√©m a lista de IDs de usu√°rios para os quais as recomenda√ß√µes devem ser geradas.</p></li>
      <li><p align="justify">Em seguida, o arquivo de sa√≠da <code>output.dat</code> √© preparado pela fun√ß√£o <code>prepareRecommendationsOutput</code>, que escreve um cabe√ßalho informativo contendo os hiperpar√¢metros da execu√ß√£o (K, N, L, etc.), garantindo a rastreabilidade dos resultados.</p></li>
    </ul>
  </li>

  <li>
    <p align="justify"><strong>Processamento Paralelizado de Recomenda√ß√µes</strong></p>
    <ul>
      <li><p align="justify">O n√∫cleo desta fase √© a fun√ß√£o <code>generateRecommendationsForUsers</code>, que orquestra a gera√ß√£o de recomenda√ß√µes para m√∫ltiplos usu√°rios de forma concorrente.</p></li>
      <li><p align="justify"><strong>Paralelismo com OpenMP:</strong> A itera√ß√£o sobre a lista de usu√°rios-alvo √© paralelizada utilizando a diretiva <code>#pragma omp parallel for</code>. Essa abordagem √© fundamental para a performance, pois divide o trabalho entre os n√∫cleos de processamento dispon√≠veis na CPU. Em vez de processar um usu√°rio de cada vez, o sistema processa v√°rios simultaneamente, transformando um problema de complexidade O(N * C) (onde N √© o n√∫mero de usu√°rios e C o custo por usu√°rio) em aproximadamente O((N / P) * C) (onde P √© o n√∫mero de n√∫cleos), garantindo alta escalabilidade.</p></li>
      <li><p align="justify"><strong>Coleta de Resultados Paralelos:</strong> Os resultados de cada thread (uma string formatada por usu√°rio) s√£o armazenados em um <code>std::vector&lt;std::string&gt;</code> pr√©-alocado com o tamanho exato da lista de usu√°rios. Esta √© uma decis√£o de design crucial para o paralelismo: ao fazer com que cada thread escreva em uma posi√ß√£o √∫nica e pr√©-determinada do vetor (<code>user_outputs[idx]</code>), elimina-se a necessidade de sincroniza√ß√£o (locks) para proteger o acesso ao cont√™iner, um padr√£o conhecido como "embarrassingly parallel". A alternativa, usar <code>push_back</code> em um vetor compartilhado, exigiria um <code>#pragma omp critical</code>, o que serializaria as inser√ß√µes e criaria um gargalo de performance.</p></li>
    </ul>
  </li>

  <li>
    <p align="justify"><strong>Pipeline de Recomenda√ß√£o por Usu√°rio</strong></p>
    <p align="justify">Para cada usu√°rio, a fun√ß√£o <code>processUserRecommendations</code> executa um pipeline bem definido:</p>
    <ol type="a">
      <li>
        <p align="justify"><strong>Busca por Vizinhos Aproximados (ANN):</strong> A fun√ß√£o <code>findApproximateKNearestNeighborsLSH</code> √© invocada. Ela usa as tabelas LSH para identificar um conjunto de usu√°rios candidatos e os armazena em um <code>std::set&lt;int&gt;</code>.<br>
          <strong>Justificativa da Estrutura:</strong> O <code>std::set</code> foi escolhido por garantir automaticamente a unicidade dos candidatos, uma vez que um mesmo usu√°rio pode ser encontrado em m√∫ltiplos "buckets" de LSH. A alternativa, um <code>std::vector</code>, exigiria uma etapa posterior de ordena√ß√£o e remo√ß√£o de duplicatas (<code>sort</code> + <code>unique</code>), que seria mais verbosa e computacionalmente cara. Embora um <code>std::unordered_set</code> (tabela de hash, O(1) de inser√ß√£o) seja teoricamente mais r√°pido que o <code>std::set</code> (√°rvore, O(log n) de inser√ß√£o), o n√∫mero de candidatos por usu√°rio √© relativamente pequeno, tornando a diferen√ßa de performance negligenci√°vel e a simplicidade do <code>std::set</code> uma escolha v√°lida.</p>
      </li>
      <li>
        <p align="justify"><strong>C√°lculo das Recomenda√ß√µes:</strong> Com a lista de vizinhos, a fun√ß√£o <code>generateRecommendationsLSH</code> calcula os scores para os filmes candidatos. A pontua√ß√£o √© uma m√©dia ponderada das notas dadas pelos vizinhos, onde o peso √© a similaridade do vizinho. O trecho-chave da l√≥gica de agrega√ß√£o √©:</p>
        <pre><code class="language-cpp">
// Em generateRecommendationsLSH.cpp
// Para cada vizinho e seus filmes avaliados...
if (target_user_seen_movies.count(movie_id)) {
  continue; // Ignora filme j√° visto
}
// Acumula a nota ponderada pela similaridade
movie_weighted_score_sum_local[thread_id][movie_id] += rating * similarity_score;
// Acumula a soma das similaridades para a normaliza√ß√£o
movie_similarity_sum_local[thread_id][movie_id] += similarity_score;
</code></pre>
      </li>
      <li><p align="justify"><strong>Filtragem e Ordena√ß√£o:</strong> As recomenda√ß√µes podem passar por um filtro que remove filmes com score previsto inferior √† m√©dia de avalia√ß√£o do pr√≥prio usu√°rio-alvo. Por fim, a lista √© ordenada de forma decrescente pela pontua√ß√£o para extrair as Top-N.</p></li>
    </ol>
  </li>

  <li>
    <p align="justify"><strong>Formata√ß√£o e Persist√™ncia dos Resultados</strong></p>
    <ul>
      <li>
        <p align="justify">Os resultados de cada usu√°rio s√£o formatados em uma string leg√≠vel usando <code>std::ostringstream</code>.Uma <code>std::ostringstream</code> √© uma stream que opera sobre um buffer de string em mem√≥ria. Ela √© mais eficiente para construir strings complexas de forma incremental do que concatena√ß√µes repetidas com <code>std::string::operator+=</code>. O motivo √© que concatena√ß√µes sucessivas podem for√ßar m√∫ltiplas realoca√ß√µes de mem√≥ria √† medida que a string cresce. A <code>ostringstream</code> gerencia seu buffer interno de forma mais inteligente, muitas vezes dobrando seu tamanho quando o espa√ßo acaba, o que minimiza o n√∫mero de opera√ß√µes de aloca√ß√£o e c√≥pia, resultando em melhor performance.</p>
      </li>
      <li><p align="justify">O vetor com as strings de todos os usu√°rios √© ent√£o percorrido, e seu conte√∫do √© escrito no arquivo <code>output.dat</code>, finalizando o processo.</p></li>
    </ul>
  </li>
</ol>


<h3 id="modulo-avaliacao">‚úÖ Avalia√ß√£o do Modelo</h3>

<p align="justify">A avalia√ß√£o da qualidade das recomenda√ß√µes geradas pelo sistema √© um processo multifacetado que vai al√©m de m√©tricas de precis√£o tradicionais, como o RMSE. Em vez disso, o foco est√° em como o sistema quantifica a relev√¢ncia de cada sugest√£o e a apresenta de forma transparente e interpret√°vel para o usu√°rio. Essa avalia√ß√£o ocorre em duas etapas principais, refletidas nas fun√ß√µes <code>generateRecommendationsLSH</code> e <code>processUserRecommendations</code>.</p>

O n√∫cleo da avalia√ß√£o reside no c√°lculo de uma **pontua√ß√£o de recomenda√ß√£o prevista** para cada filme. Este score √© uma m√©dia ponderada das avalia√ß√µes dos vizinhos mais pr√≥ximos (usu√°rios com gostos similares), onde o peso de cada avalia√ß√£o √© a similaridade de cosseno entre o vizinho e o usu√°rio-alvo. A f√≥rmula matem√°tica para a pontua√ß√£o prevista ($P_{u,i}$) para um usu√°rio $u$ e um item (filme) $i$ √©:

$$P_{u,i} = \frac{\sum_{v \in N} sim(u,v) \cdot r_{v,i}}{\sum_{v \in N} |sim(u,v)|}$$

Onde cada componente da f√≥rmula significa:

* **$N$**: √â o conjunto de vizinhos do usu√°rio $u$ que tamb√©m avaliaram o item $i$.
* **$sim(u, v)$**: √â a similaridade de cosseno (ou outra m√©trica) entre o usu√°rio-alvo $u$ e um vizinho $v$.
* **$r_{v,i}$**: √â a nota (rating) que o vizinho $v$ deu ao item $i$.

Em ess√™ncia, a opini√£o de vizinhos mais parecidos tem um peso maior, tornando a recomenda√ß√£o mais personalizada e confi√°vel.
<p align="justify">Para refinar ainda mais a qualidade, o sistema pode aplicar um filtro opcional que considera a m√©dia de avalia√ß√£o do pr√≥prio usu√°rio-alvo. Se ativado, apenas os filmes com uma pontua√ß√£o prevista superior a essa m√©dia s√£o recomendados, focando em sugest√µes que t√™m maior probabilidade de superar as expectativas do usu√°rio.</p>

<p align="justify">Finalmente, a apresenta√ß√£o dos resultados √©, por si s√≥, uma forma de avalia√ß√£o. O sistema exibe a <strong>similaridade m√©dia dos vizinhos</strong>, que funciona como um indicador de confian√ßa: quanto maior a similaridade, mais confi√°vel √© a base da recomenda√ß√£o. Al√©m disso, a pontua√ß√£o prevista √© convertida para um percentual de relev√¢ncia (de 0 a 100%) e as recomenda√ß√µes s√£o ranqueadas em ordem decrescente. Isso permite que o usu√°rio compreenda n√£o apenas quais filmes s√£o sugeridos, mas tamb√©m o qu√£o forte √© cada recomenda√ß√£o e em que base de similaridade ela se apoia.</p>

<h2 id="resultados">üìä An√°lise de Resultados</h2>

Ap√≥s o pr√©-processamento, com as restri√ß√µes impostas, foram identificados 102.492 usu√°rios e 13.176 filmes v√°lidos, representando uma redu√ß√£o de aproximadamente 37% no n√∫mero de usu√°rios e 79% no n√∫mero de filmes em rela√ß√£o ao conjunto original, que continha 162.541 usu√°rios e 62.423 filmes

Na tentativa de validar o modelo proposto e analisar a melhor configura√ß√£o dos par√¢metros que conciliem desempenho e performance, foram examinados as combina√ß√µes relacionadas ao n√∫mero de tabelas hash e o n√∫mero de hiperplanos. Ambos par√¢metros influenciam diretamente na qualidade da recomenda√ß√£o e na performance. Atrelado a essas duas caracter√≠sticas avaliou-se para um usu√°rio -  usu√°rio 3 (escolha aleat√≥ria) - , o valor da similaridade m√©dia deste usu√°rio e com seus vizinhos. A ado√ß√£o dessa abordagem est√° inserida no contexto de que: a qualidade das recomenda√ß√µes dos filmes basea-se na multiplica√ß√£o da similaridade e a nota dada ao filme pelo vizinho. Assim, quanto maior a similaridade, maior a tend√™ncia de boas indica√ß√µes para o usu√°rio-alvo.
Todas as modifica√ß√µes atreladas aos par√¢metros ocorreram no arquivo config.hpp. Foram utilizados os seguintes valores:
<pre><code>// Recommendation & Filtering Parameters
const int MIN_RATINGS_PER_ENTITY = 50; 
const int K_NEIGHBORS = 10;
const size_t NUM_RANDOM_USERS_TO_EXPLORE = 50;
const int TOP_N_RECOMMENDATIONS = 5;

// cd Parameters lsh
const int NUM_LSH_TABLES = x ;
const int NUM_HYPERPLANES_PER_TABLE = y;    
</code></pre>


1. **Varia√ß√£o do n√∫mero de tabelas hash e n√∫mero de hiperplanos constante**

Para o arranjo proposto foram executados testes sucessivos em que o n√∫mero de hiperplanos foram mantidos constante <code> NUM_HYPERPLANES_PER_TABLE = 16 </code>, e o n√∫mero de tabelas hash variando de 1 at√© 16. A escolha para o n√∫mero de hiperplanos est√° atrelado ao fato de possuir o conjunto de dados com mais de 100 mil usu√°rios, que em bin√°rio, s√£o necess√°rios 16 bits. Os dados obtidos os de tempo de execu√ß√£o e valor da similaridade m√©dia encontra-se no gr√°fico abaixo:

<p align="center">
  <img src="https://hackmd.io/_uploads/SyX1erg8eg.png" alt="Diagrama LSH" width="500"/>
  <br>
  <em>Figura 1: Varia√ß√£o no n√∫mero de tabelas hash e n√∫mero de hiperplanos constante. As barras em azul est√£o atreladas ao tempo de execu√ß√£o e a linha em vermelha a similaridade m√©dia. O aumento no n√∫mero de tabelas hash aumenta o tempo de execu√ß√£o, mas existe um limiar para o incremento da similaridade que se mant√©m em um valor constante de 0.47 ap√≥s o valor de 7.</em>
</p>

Uma interpreta√ß√£o do gr√°fico indica que existe um limiar para o valor da similaridade (0.47) a medida que o n√∫mero de tabelas hash aumenta. E como esperado, o aumento no n√∫mero de tabelas hash provoca um incremento no tempo de execu√ß√£o. Devido a natureza do problema, em que perfomance, isto √©, menor tempo de execu√ß√£o √© uma vantagem, a defini√ß√£o mais consistente do n√∫mero de tabelas hash √© de 7. Uma vez que apresenta um balan√ßo de tempo e valor de similaridade.Quanto aos poss√≠veis picos de tempo, uma explica√ß√£o plaus√≠vel para as flutua√ß√µes observadas no sistema reside na variabilidade da aloca√ß√£o de recursos computacionais durante o processamento paralelo. Interfer√™ncias como carga concorrente do sistema operacional, balanceamento imperfeito entre threads ou at√© mesmo varia√ß√µes na distribui√ß√£o dos usu√°rios entre os buckets podem introduzir essas instabilidades pontuais no tempo de execu√ß√£o.


2. **Varia√ß√£o do n√∫mero de tabelas hash e hiperplanos**

A abordagem da varia√ß√£o do n√∫mero de hiperplanos e n√∫mero de tabelas hash consistiu em variar ambos os par√¢metros de 1 a 16. Os resultados obtidos encontram-se no gr√°fico abaixo:


<p align="center">
  <img src="https://hackmd.io/_uploads/HkkGxBlLxl.png" alt="Diagrama LSH" width="500"/>
  <br>
  <em>Figura 2: Varia√ß√£o no n√∫mero de tabelas hash e n√∫mero de hiperplanos. As barras em azul est√£o atreladas ao tempo de exeu√ß√£o e a linha em vermelha a similaridade m√©dia. O aumento no n√∫mero de tabelas hash e hiperplanos aumenta o tempo de execu√ß√£o, e provoca uma redu√ß√£o do valor da similaridade que cai de aproximadamente 0.60 para 0.47. Verifica-se que o valor de 7 para ambos os par√¢metros mant√©m performace e qualidade de recomenda√ß√£o.</em>
</p>

Uma an√°lise do gr√°fico permite concluir que o aumento de ambos os par√¢metros provoca um aumento no tempo de execu√ß√£o, e uma redu√ß√£o no valor de similaridade. Caracter√≠sticas nos quais n√£o s√£o desejadas. A redu√ß√£o se faz jus pois a medida que se aumenta a quantidade de hiperplanos gera-se buckets cada vez mais espec√≠ficos reduzindo assim a probabilidade de colis√µes e consequentemente de usu√°rios dentro de um bucket. Dessa forma, partindo dos resultados do gr√°fico infere-se que o valor de  7 tabelas hash e 7 hiperplanos mant√©m a qualidade e performance do algoritmo. 


3. **Varia√ß√£o do n√∫meros de hiperplanos e n√∫mero de tabelas hash constante**

Basedo no resultado anterior em que se variou o n√∫mero de hiperplanos de e manteve-se o n√∫mero de tabelas hash, no qual definiu-se o valor de 7 para ambos esses par√¢metros. Manteve-se o n√∫mero de tabelas hash em 7 e variou-se o n√∫mero de hiperplanos. O gr√°fico abaixo apresenta os resultados obtidos.


<p align="center">
  <img src="https://hackmd.io/_uploads/rJIXxSx8el.png" alt="Diagrama LSH" width="500"/>
  <br>
  <em>Figura 3: Varia√ß√£o no n√∫mero de hiperplanos e  n√∫mero de tabelas hash constante. As barras em azul est√£o atreladas ao tempo de exeu√ß√£o e a linha em vermelha a similaridade m√©dia. O aumento no n√∫mero de tabelas hash aumenta o tempo de execu√ß√£o, e provoca uma redu√ß√£o no valor da similaridade que cai de aproximadamente 0.60 para 0.27. Verifica-se que o valor de 7 mant√©m performance e qualidade de recomenda√ß√£o.</em>
</p>

A investiga√ß√£o do gr√°fico mostrou que o aumento do n√∫mero de hiperplanos provoca uma redu√ß√£o da similaridade e um aumento no tempo de execu√ß√£o. Este resultado j√° foi observado em an√°lises anteriores. Observando os valores, novamente para 7 hiperplanos nota-se uma consist√™ncia para a similaridade e tempo de execu√ß√£o. No entanto, nota-se que para o intervalo de 5-7 um valor constante para similaridade e tempo de execu√ß√£o. Assim, a escolha para o n√∫mero de hiplerplanos pode estar dentro desse intervalo, uma vez que n√£o indicou provocar altera√ß√µes subst√¢ncias nos resultados. 

Analisando os tr√™s combina√ß√µes propostas, verificamos que o n√∫mero m√≠nimo de tabelas hash √© 7 e o n√∫mero de hiperplanos √© 5. Esses valores equilibram performance e qualidade de recomenda√ß√£o.

<h3> Teste de recomenda√ß√µes </h3>

Afim de verificar a qualidade das recomenda√ß√µes geradas pelo algoritmo foram testados dois casos:
1. **Recomenda√ß√µes em um mesmo bucket**

    Para verificar a consist√™ncia da gera√ß√£o de recomenda√ß√µes em uma mesma execu√ß√£o, o arquivo explore.dat foi manipulado para incluir um usu√°rio duplicado. Essa abordagem permite analisar se, ao processar o mesmo usu√°rio mais de uma vez, o sistema retorna recomenda√ß√µes id√™nticas, evidenciando que o algoritmo de LSH est√° determin√≠stico e que usu√°rios que caem no mesmo bucket recebem resultados consistentes. Caso haja diverg√™ncia nas recomenda√ß√µes para o mesmo usu√°rio, isso pode indicar algum fator aleat√≥rio n√£o controlado ou instabilidade na constru√ß√£o dos buckets LSH.
    Para o teste, escolheu-se o usu√°rio 1, cujos resultados para a execu√ß√£o est√£o dispon√≠veis abaixo:
    ````
    User ID: 1 | Similaridade Media: 0.23
      Recommended Movies (MovieID: Score | Title):
      - 750: 95.0% | Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964),Comedy|War
      - 3083: 94.1% | All About My Mother (Todo sobre mi madre) (1999),Drama
      - 2019: 90.2% | Seven Samurai (Shichinin no samurai) (1954),Action|Adventure|Drama
      - 50: 87.8% | Usual Suspects, The (1995)
      - 3910: 86.4% | Dancer in the Dark (2000),Drama|Musical

    User ID: 1 | Similaridade Media: 0.23
     Recommended Movies (MovieID: Score | Title):
      - 750: 95.0% | Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964),Comedy|War
      - 3083: 94.1% | All About My Mother (Todo sobre mi madre) (1999),Drama
      - 2019: 90.2% | Seven Samurai (Shichinin no samurai) (1954),Action|Adventure|Drama
      - 50: 87.8% | Usual Suspects, The (1995)
      - 3910: 86.4% | Dancer in the Dark (2000),Drama|Musical
     ````
     Observa-se que, para o usu√°rio 1, as recomenda√ß√µes geradas nas duas ocorr√™ncias s√£o absolutamente id√™nticas, tanto na lista de filmes sugeridos quanto nos respectivos scores e t√≠tulos. Al√©m disso, a similaridade m√©dia dos vizinhos encontrados permanece exatamente igual nas duas execu√ß√µes (0.23). Isso evidencia que o sistema est√° funcionando de forma determin√≠stica: ao processar o mesmo usu√°rio, mesmo que duplicado no arquivo de entrada, o algoritmo LSH+KNN retorna resultados consistentes e reprodut√≠veis.

    Esse comportamento confirma que a constru√ß√£o dos buckets LSH, a busca de vizinhos e a gera√ß√£o das recomenda√ß√µes n√£o dependem de fatores aleat√≥rios n√£o controlados, e que o uso de uma semente fixa para o gerador de n√∫meros aleat√≥rios est√° garantindo a estabilidade do sistema. Portanto, usu√°rios que caem no mesmo bucket (ou, neste caso, o mesmo usu√°rio processado duas vezes) recebem sempre as mesmas recomenda√ß√µes, o que √© desej√°vel para an√°lises comparativas e para garantir confiabilidade nos resultados do sistema de recomenda√ß√£o.
    
    Um outro fator observado, √© que a indica√ß√£o de filmes que reflete o perfil do usu√°rio mostra-se consistente. Atrav√©s do arquivo auxiliar `user_most_frequent_genres.dat` gerado em Python, √© poss√≠vel mapear a quantidade de filmes assistidos por g√™nero pelo usu√°rio-alvo.
    ````
    User 1:
      Drama: 53
      Comedy: 23
      Romance: 18
      Adventure: 11
      Crime: 8
      Thriller: 5
      War: 5
      Musical: 5
      Sci-Fi: 5
      Fantasy: 5
      Mystery: 4
      Action: 4
      Children: 3
      Animation: 2
      Film-Noir: 1
      Western: 1
      Documentary: 1
      Horror: 1
    ````
     
     Quando se compara a lista de filmes recomendados para o usu√°rio 1 com o seu perfil de g√™neros mais assistidos, observa-se uma forte coer√™ncia entre as sugest√µes do sistema e os interesses reais do usu√°rio. Por exemplo, entre os cinco filmes recomendados, predominam os g√™neros Drama, Comedy, War, Musical e Adventure, que est√£o entre os mais frequentes no hist√≥rico do usu√°rio. Filmes como "Dr. Strangelove" (Comedy|War), "All About My Mother" (Drama), "Seven Samurai" (Action|Adventure|Drama), "Usual Suspects" (Crime|Thriller) e "Dancer in the Dark" (Drama|Musical) refletem diretamente essa prefer√™ncia.

    Essa correspond√™ncia refor√ßa a qualidade do algoritmo de recomenda√ß√£o, mostrando que, al√©m de ser determin√≠stico e est√°vel, o sistema √© capaz de capturar nuances do perfil do usu√°rio e sugerir t√≠tulos alinhados com seus gostos predominantes. 
    
2. **Recomenda√ß√£o para um usu√°rio espec√≠fico**

   Para exemplificar o funcionamento do sistema de recomenda√ß√£o diante de perfis com prefer√™ncia marcante por um g√™nero espec√≠fico, foi selecionado o usu√°rio 2177, que apresenta alto consumo de filmes de drama segundo o arquivo user_most_frequent_genres.dat. A seguir, s√£o apresentadas as recomenda√ß√µes geradas para esse usu√°rio, permitindo observar como o algoritmo responde a padr√µes de consumo bem definidos e prioriza t√≠tulos alinhados √†s prefer√™ncias individuais.
    
    ````
    User 2177:
      Drama: 2116
      Comedy: 1692
      Romance: 943
      Thriller: 794
      Action: 655
      Adventure: 532
      Crime: 497
      Sci-Fi: 300
      Horror: 273
      Children: 269
      Mystery: 269
      Fantasy: 259
      Musical: 256
      War: 205
      Western: 147
      Animation: 103
      Film-Noir: 68
      Documentary: 45
      IMAX: 19
    ````
    O resultado da recomenda√ß√£o
    ````
    User ID: 2177 | Similaridade Media: 0.63
      Recommended Movies (MovieID: Score | Title):
      - 177593: 100.0% | Three Billboards Outside Ebbing, Missouri (2017)
      - 116136: 100.0% | Olive Kitteridge (2014),Drama
      - 26395: 100.0% | Rutles: All You Need Is Cash, The (1978)
      - 47721: 95.7% | Red Balloon, The (Ballon rouge, Le) (1956)
      - 74508: 95.0% | Persuasion (2007),Drama|Romance
    ````
    
    √â poss√≠vel perceber que o sistema de recomenda√ß√£o reconhece o padr√£o de consumo do usu√°rio 2177, que possui uma forte prefer√™ncia pelo g√™nero "Drama" (com 2116 filmes assistidos desse tipo). Entre os filmes recomendados, destacam-se t√≠tulos como "Olive Kitteridge (2014)" e "Persuasion (2007)", ambos classificados como Drama, al√©m de outros filmes que frequentemente combinam Drama com Romance ou outros g√™neros apreciados pelo usu√°rio. A similaridade m√©dia elevada (0.63) indica que as recomenda√ß√µes s√£o altamente relevantes para o perfil do usu√°rio, evidenciando que o algoritmo LSH+KNN √© capaz de identificar e priorizar os g√™neros mais consumidos, proporcionando sugest√µes alinhadas √†s prefer√™ncias individuais.
3. **Recomenda√ß√£o para um usu√°rio diverso**
    
    Para verificar a performance do algoritmo de recomenda√ß√£o em cen√°rios onde o usu√°rio possui um perfil muito diverso ‚Äî ou seja, consome filmes de v√°rios g√™neros com frequ√™ncia relativamente equilibrada ‚Äî √© importante analisar se o sistema consegue identificar vizinhos relevantes e sugerir t√≠tulos que realmente reflitam essa diversidade. Usu√°rios com gostos amplos representam um desafio para sistemas baseados em similaridade, pois podem ter menos sobreposi√ß√£o direta com outros perfis, tornando a busca por vizinhos pr√≥ximos mais dif√≠cil.
    Tomando um exemplo, o usu√°rio 2
    ````
    User 3:
      Action: 334
      Thriller: 239
      Drama: 232
      Sci-Fi: 224
      Adventure: 198
      Comedy: 176
      Crime: 132
      IMAX: 81
      Fantasy: 78
      Mystery: 60
      Romance: 60
      Animation: 50
      Children: 48
      Horror: 45
      War: 26
      Western: 8
      Musical: 6
      Film-Noir: 5
      Documentary: 3
      (no genres listed): 1
    ````
      E ao comparar sua recomenda√ß√£o:
      
      ````
      User ID: 3 | Similaridade Media: 0.57
      Recommended Movies (MovieID: Score | Title):
      - 85774: 100.0% | Senna (2010),Documentary
      - 171011: 100.0% | Planet Earth II (2016),Documentary
      - 98491: 94.9% | Paperman (2012),Animation|Comedy|Romance
      - 159817: 93.3% | Planet Earth (2006),Documentary
      - 47: 92.5% | Seven (a.k.a. Se7en) (1995),Mystery|Thriller
      ````
      Nota-se que, apesar do perfil extremamente diverso do usu√°rio 3 ‚Äî que consome filmes de praticamente todos os g√™neros com frequ√™ncia significativa ‚Äî o sistema de recomenda√ß√£o conseguiu sugerir t√≠tulos que refletem essa variedade. Entre os filmes recomendados, h√° document√°rios ("Senna", "Planet Earth II", "Planet Earth"), anima√ß√£o e com√©dia rom√¢ntica ("Paperman"), al√©m de suspense e mist√©rio ("Seven"). Isso demonstra que o algoritmo LSH+KNN √© capaz de identificar vizinhos relevantes mesmo para usu√°rios com gostos amplos, e de gerar recomenda√ß√µes que abrangem diferentes g√™neros presentes no hist√≥rico do usu√°rio.

    Al√©m disso, a similaridade m√©dia dos vizinhos encontrados (0.57) √© relativamente alta, indicando que o sistema conseguiu localizar perfis pr√≥ximos, mesmo diante da diversidade de interesses. A presen√ßa de document√°rios entre os principais recomendados, por exemplo, mostra que o sistema √© sens√≠vel a nuances do perfil do usu√°rio, n√£o se limitando apenas aos g√™neros mais populares, mas tamb√©m incluindo t√≠tulos de nicho que fazem parte do seu hist√≥rico.

<h3>Comsumo de m√©moria</h3>

Para avaliar o consumo de mem√≥ria do algoritmo, √© fundamental considerar os par√¢metros utilizados, pois eles impactam diretamente a quantidade de dados armazenados e processados durante a execu√ß√£o. A an√°lise do uso de mem√≥ria √© importante para garantir que o sistema seja eficiente e escal√°vel, especialmente ao lidar com grandes volumes de dados ou ao ajustar par√¢metros como o n√∫mero de tabelas LSH, hiperplanos.


<div style="display: flex; justify-content: center; gap: 40px; flex-wrap: wrap; margin-bottom: 10px;">

  <div style="text-align: center;">
    <img src="https://hackmd.io/_uploads/H1b5JuxUxe.png" alt="memoria_1_1" width="400"/>
    <div>(a)</div>
  </div>

  <div style="text-align: center;">
    <img src="https://hackmd.io/_uploads/S1Zq1Ox8gx.png" alt="memoria_5_5" width="400"/>
    <div>(b)</div>
  </div>

  <div style="text-align: center; margin-top: 20px;">
    <img src="https://hackmd.io/_uploads/r1Zq1OlIgx.png" alt="memoria_7_5" width="400"/>
    <div>(c)</div>

  </div>

  <div style="text-align: center; margin-top: 20px;">
    <img src="https://hackmd.io/_uploads/HkZcJOxIeg.png" alt="memoria_16_16" width="400"/>
    <div>(d)</div>
  </div>

</div>

<p style="text-align: center; font-size: 14px; color: #4b5563; margin-top: 10px;">
  <em>Figura 1: Uso de mem√≥ria para diferentes configura√ß√µes de par√¢metros LSH associado ao n√∫mero de tabelas hash e hiperplanos (lxk) ‚Äî (a) 1x1, (b) 5x5, (c) 7x5 e (d) 16x16. Nota-se que a medida que se aumenta os param√™tros o consumo de mem√≥ria em uso se mant√©m prolongado, no entanto, com pico constante de 853.5 MB. </em>
</p>


Os gr√°ficos apresentados na Figura 1 ilustram o uso de mem√≥ria para diferentes configura√ß√µes dos par√¢metros LSH, variando o n√∫mero de tabelas hash e hiperplanos (l √ó k): (a) 1√ó1, (b) 5√ó5, (c) 7√ó5 e (d) 16√ó16. Observa-se que, √† medida que os par√¢metros aumentam, o consumo de mem√≥ria se mant√©m elevado por mais tempo durante a execu√ß√£o. Isso ocorre porque o aumento no n√∫mero de tabelas e hiperplanos faz com que o sistema construa e mantenha estruturas de dados mais complexas e volumosas, exigindo que essas estruturas permane√ßam acess√≠veis at√© o t√©rmino do processamento. Como resultado, a mem√≥ria √© intensamente utilizada por um per√≠odo prolongado, refletindo o maior volume de dados processados. No entanto, o pico de uso permanece constante em torno de 850 MB, indicando que o algoritmo consegue manter o consumo m√°ximo de mem√≥ria sob controle mesmo em cen√°rios mais exigentes. Isso demonstra a efici√™ncia do sistema em gerenciar recursos computacionais, permitindo ajustes nos par√¢metros sem comprometer a estabilidade do ambiente.

<h2 id="conclusao">‚úîÔ∏è Conclus√£o</h2>

<p align="justify">
Este projeto demonstrou com sucesso a viabilidade e a efic√°cia da implementa√ß√£o de um sistema de recomenda√ß√£o de filmes capaz de lidar com a escala e a complexidade de um grande volume de dados, como o do dataset <b>MovieLens 25M</b>. Ao confrontar diretamente as limita√ß√µes de escalabilidade de algoritmos tradicionais como o k-NN, cuja complexidade computacional se torna proibitiva em cen√°rios de alta dimensionalidade, a abordagem h√≠brida adotada se mostrou uma solu√ß√£o robusta e perform√°tica.
</p>

<p align="justify">
A implementa√ß√£o em C++, otimizada com paraleliza√ß√£o via OpenMP e estruturas de dados eficientes da STL, estabeleceu uma base s√≥lida para o processamento de milh√µes de avalia√ß√µes. O ponto central do sucesso do projeto foi a aplica√ß√£o estrat√©gica da t√©cnica de <b>Hashing Sens√≠vel √† Localidade (LSH)</b> como um mecanismo de filtragem inteligente. O LSH mitigou efetivamente a "maldi√ß√£o da dimensionalidade", reduzindo drasticamente o espa√ßo de busca ao agrupar usu√°rios com perfis de gosto similares em "buckets" com alta probabilidade. Essa busca aproximada, com sua complexidade sublinear, resolveu o principal gargalo de performance identificado na fundamenta√ß√£o te√≥rica. A an√°lise de resultados validou empiricamente a metodologia, revelando que uma configura√ß√£o otimizada com 7 tabelas LSH e 5 hiperplanos oferece o melhor equil√≠brio entre o tempo de execu√ß√£o e a qualidade das recomenda√ß√µes, mantendo a similaridade m√©dia em um patamar elevado sem incorrer em custos computacionais excessivos.
</p>

<p align="justify">
Ao combinar a velocidade do LSH para a sele√ß√£o de um conjunto de candidatos promissores com a precis√£o da similaridade de cosseno para a sele√ß√£o final dos vizinhos mais pr√≥ximos, o sistema alcan√ßou um equil√≠brio not√°vel entre efici√™ncia e qualidade das recomenda√ß√µes. A valida√ß√£o qualitativa, comparando as sugest√µes geradas com os perfis de g√™nero dos usu√°rios, confirmou que o algoritmo √© capaz de gerar recomenda√ß√µes coerentes e personalizadas tanto para usu√°rios de nicho quanto para aqueles com gostos diversificados. Al√©m disso, a reprodutibilidade do sistema foi assegurada, demonstrando que, para um mesmo usu√°rio, as recomenda√ß√µes s√£o determin√≠sticas e consistentes.
</p>

<p align="justify">
Como trabalhos futuros, o sistema poderia ser expandido de v√°rias maneiras. A primeira seria a implementa√ß√£o de um mecanismo de atualiza√ß√£o online para as tabelas LSH, permitindo que o modelo se adapte a novas avalia√ß√µes em tempo real sem a necessidade de reconstruir todos os √≠ndices. Adicionalmente, a explora√ß√£o de outros m√©todos de LSH, como aqueles baseados em distribui√ß√µes p-est√°veis, ou a incorpora√ß√£o de dados contextuais, como as tags e os g√™neros dos filmes, no processo de vetoriza√ß√£o, poderia refinar ainda mais a relev√¢ncia e a personaliza√ß√£o das sugest√µes, aprimorando a experi√™ncia do usu√°rio final.
</p>

<h2 id="ambiente">üöÄ Ambiente Compila√ß√£o e Execu√ß√£o</h2>

Este projeto foi executado utilizando:
  * **Sistema Operacional**: Linux Ubuntu WSL @ Windows 11 (Windows Subsystem for Linux).
  * **Compilador**: GCC 13.3.0
  * **Hardware**: 13th Gen Intel(R) Core(TM) i7-13620H @ 2.40GHz, 24GB RAM, 512GB SSD, NVIDIA GeForce RTX 4050.
  

Para a compila√ß√£o do projeto √© necessario seguir alguns passos antes da execu√ß√£o: 

* **Clonar o reposit√≥rio** 
<pre> git clone https://github.com/PeedroHG/RecommendationAlgorithm 
cd RecommendationAlgorithm  </pre>
* **Organiza√ß√£o dos arquivos de entrada** 

Este projeto utiliza dados do conjunto [MovieLens 25M](https://grouplens.org/datasets/movielens/25m/).
Ap√≥s o download, √© necessario certificar de que os seguintes arquivos estejam na pasta dataset/ na raiz do projeto
```text
üìÇ dataset/ 
‚îú‚îÄ‚îÄ ratings.csv
‚îú‚îÄ‚îÄ movies.csv
```
* **Compilar o projeto**

Para compilar o projeto √© utilizado um arquivo Makefile como script de automa√ß√£o para compilar  projeto. Esse arquivo define regras que simplificam o processo da compila√ß√£o.

Para compilar o projeto de maneira padr√£o, de acordo com o arquio Makefile
<pre>make</pre>
Ap√≥s compilar o projeto, o mesmo pode ser executado
<pre>make run</pre>
Ao final desse processo, os resultados do projeto executado estar√° no arquivo output.dat

Para a limpeza dos arquivos gerados
<pre>make clean</pre>

<h2 id="arquivos">üìÅ Arquivos Adicionais</h2>

<b>Gera√ß√£o de Perfis de G√™nero</b>

Para fundamentar a an√°lise qualitativa das recomenda√ß√µes geradas pelo algoritmo principal, foi desenvolvido um script auxiliar em Python. O objetivo deste m√≥dulo √© processar os dados brutos e construir um perfil detalhado para cada usu√°rio, quantificando seus interesses com base nos g√™neros dos filmes que j√° assistiram.

O script que pode ser encontrado no [Google Collab](https://colab.research.google.com/drive/1h6yweLM0G7yanU6hY_rLDDC489Di15fv?usp=sharing), utiliza como entrada os arquivos ```ratings.csv``` e ```movies.csv``` e aplica o mesmo crit√©rio de filtragem do pipeline em C++  (considera apenas usu√°rios que avaliaram 50 ou mais filmes). Para cada usu√°rio v√°lido, o script analisa seu hist√≥rico, extrai os g√™neros de cada filme e agrega a contagem total por g√™nero. O resultado √© um arquivo de sa√≠da ```user_most_frequent_genres.dat``` que mapeia cada ID de usu√°rio ao seu perfil de consumo, como no exemplo abaixo:

```
User 1:
  Drama: 53
  Comedy: 23
  Romance: 18
  Adventure: 11
  Crime: 8
  ...
```

Este perfil de g√™nero serve como uma base de refer√™ncia essencial na se√ß√£o seguinte de An√°lise de Resultados. Com ele, √© poss√≠vel n√£o apenas verificar se as recomenda√ß√µes geradas s√£o coerentes com os gostos predominantes de um usu√°rio, mas tamb√©m classificar os usu√°rios entre perfis de nicho (concentrados em poucos g√™neros) e perfis dispersos (com interesses variados), permitindo uma avalia√ß√£o mais robusta da efic√°cia do algoritmo em diferentes cen√°rios.



<h2 id="autores"> üë• Autores</h2>

* [<img src="https://cdn.jsdelivr.net/npm/simple-icons@latest/icons/github.svg" width="24" alt="GitHub">](https://github.com/peixotoigor) Igor Peixoto
* [<img src="https://cdn.jsdelivr.net/npm/simple-icons@latest/icons/github.svg" width="24" alt="GitHub">](https://github.com/PeedroHG) Pedro Galv√£o
* [<img src="https://cdn.jsdelivr.net/npm/simple-icons@latest/icons/github.svg" width="24" alt="GitHub">](https://github.com/joaopaulocruzdefaria) Jo√£o Cruz
* [<img src="https://cdn.jsdelivr.net/npm/simple-icons@latest/icons/github.svg" width="24" alt="GitHub">](https://github.com/Lucas-Roseno) Lucas Roseno
* [<img src="https://cdn.jsdelivr.net/npm/simple-icons@latest/icons/github.svg" width="24" alt="GitHub">](https://github.com/LuizFernandosq) Luiz Santos

<details id="referencias">
  <summary><b>üìö Refer√™ncias</b></summary>
  <ol>
    <li id="ref1">ALMANSOORI, Mahmood KM; MESZAROS, Andras; TELEK, Miklos. Fast and memory-efficient approximate minimum spanning tree generation for large datasets. Arabian Journal for Science and Engineering, v. 50, n. 2, p. 1233-1246, 2025.</li>
    <li id="ref2">PANDIT, Gaurav; R√ñDER, Michael; NGONGA NGOMO, Axel-Cyrille. Evaluating Approximate Nearest Neighbour Search Systems on Knowledge Graph Embeddings. In: European Semantic Web Conference. Springer, Cham, 2025. p. 59-76.</li>
    <li id="ref3">YAMAMURA, Hugo Hiroshi. R ‚Äì E. 2025. Dispon√≠vel em: https://acervodigital.ufpr.br/xmlui/bitstream/handle/1884/93822/R%20-%20E%20-%20HUGO%20HIROSHI%20YAMAMURA.pdf?sequence=1&isAllowed=y. Acesso em: 2 jun. 2025.</li>
    <li id="ref4">ANASTASIU, David C.; KARYPIS, George. Fast parallel cosine k-nearest neighbor graph construction. In: 2016 6th Workshop on Irregular Applications: Architecture and Algorithms (IA3). IEEE, 2016. p. 50-53.</li>
    <li id="ref5">HYV√ñNEN, Ville et al. Fast k-nn search. arXiv preprint arXiv:1509.06957, 2015.</li>
    <li id="ref6">FU, Jiuzhou; ZHAO, Dongfang. MPAD: A New Dimension-Reduction Method for Preserving Nearest Neighbors in High-Dimensional Vector Search. arXiv preprint arXiv:2504.16335, 2025.</li>
    <li id="ref7">RABBANI, Tahseen; BORNSTEIN, Marco; HUANG, Furong. Large-scale distributed learning via private on-device lsh. Advances in Neural Information Processing Systems, v. 36, p. 16153-16171, 2023.</li>
    <li id="ref8">ZHANG, Kunpeng; FAN, Shaokun; WANG, Harry Jiannan. An efficient recommender system using locality sensitive hashing. 2018.</li>
    <li id="ref9">LESKOVEC, J.; RAJARAMAN, A.; ULLMAN, J. D. Mining of Massive Datasets, Cambridge University Press, Cambridge [em linha]. 2014.</li>
    <li id="ref10">INDYK, Piotr; MOTWANI, Rajeev. Approximate nearest neighbors: towards removing the curse of dimensionality. In: Proceedings of the thirtieth annual ACM symposium on Theory of computing. 1998. p. 604-613.</li>
  </ol>
</details>
