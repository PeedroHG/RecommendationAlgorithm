# üé• Movie Recommendation Algorithm 

<details>
  <summary><b>üß≠ Sum√°rio</b></summary>
  <ol>
    <li><a href="#introducao">üìò Introdu√ß√£o</a></li>
    <li><a href="#fundamentacao">üìñ Abordagem e Fundamenta√ß√£o Te√≥rica</a></li>
    <li><a href="metodologia">üß™ Metodologia</a></li>
    <li><a href="#datasets">üìà Datasets</a></li>
    <li><a href="#estrutura">üß¨ Estrutura do Projeto</a></li>
    <li><a href="#modelagem-e-implementacao">üíª Modelagem e Implementa√ß√£o</a></li>
    <li><a href="ambiente">üöÄ Ambiente Compila√ß√£o e Execu√ß√£o</a></li>
    <li><a href="analises-dos-resultados">üìä An√°lises dos Resultados</a></li>
    <li><a href="conclusao">‚úîÔ∏è Conclus√£o</a></li>
    <li><a href="#autores">üë• Autores</a></li>
    <li><a href="#referencias">üìö Refer√™ncias</a></li>
  </ol>
</details>

<h2 id="introducao">üìò Introdu√ß√£o</h2>

<p align="justify">
Com o r√°pido avan√ßo tecnol√≥gico e a populariza√ß√£o da internet, o volume de dados gerados diariamente cresceu exponencialmente. Essa vasta quantidade de informa√ß√£o, embora rica, apresenta um desafio significativo: como process√°-la e transform√°-la em algo √∫til e significativo para os usu√°rios?

Essa sobrecarga de informa√ß√£o pode levar a uma sensa√ß√£o de desorienta√ß√£o. Em plataformas de streaming de v√≠deo, por exemplo, a imensa disponibilidade de t√≠tulos, apesar de ser uma vantagem, pode gerar insatisfa√ß√£o, pois o usu√°rio se sente sobrecarregado com tantas op√ß√µes de escolha. Nesse contexto, os sistemas de recomenda√ß√£o surgem como uma solu√ß√£o. Eles atuam como filtros inteligentes, avaliando as informa√ß√µes dispon√≠veis sobre o hist√≥rico e os prov√°veis interesses dos usu√°rios para, ent√£o, sugerir conte√∫dos. As recomenda√ß√µes geradas por esses sistemas n√£o apenas reduzem a sobrecarga de escolha, mas tamb√©m ajudam os usu√°rios a descobrir o que √© mais relevante e adequado aos seus gostos. Assim, transformam a abund√¢ncia de dados em uma experi√™ncia personalizada e satisfat√≥ria.

Este projeto tem como objetivo desenvolver um prot√≥tipo de algoritmo de recomenda√ß√£o de filmes, baseado na an√°lise dos perfis dos usu√°rios e nas caracter√≠sticas dos itens dispon√≠veis. A abordagem adotada busca identificar padr√µes de prefer√™ncias e comportamentos para oferecer sugest√µes personalizadas, aprimorando a experi√™ncia do usu√°rio e a relev√¢ncia das recomenda√ß√µes.
</p>

<h2 id="fundamentacao">üìñ Abordagem e Fundamenta√ß√£o Te√≥rica</h2>
<p align="justify">
No contexto deste estudo, onde foi empregado o conjunto de dados <b>MovieLens 25M</b> caracterizado pelo elevado volume de registros e alta dimensionalidade, a escolha de um m√©todo eficiente para gerar recomenda√ß√µes se faz uma tarefa desafiadora, ¬†pois √© preciso conciliar escalabilidade, velocidade de processamento e qualidade preditiva diante da esparsidade e complexidade do dataset.

Algoritmos tradicionais como k-NN tradicional ou similaridade de cosseno direta, falham em oferecer baixa escabildiade e baixa velocidade de processamento para um alto volume de dados. O primeiro falha pois para encontrar os vizinhos mais pr√≥ximos, calcula a dist√¢ncia ou similaridade de um ponto de consulta para todos os outros pontos no conjunto de dados. Isso leva a um alto custo computacional, que cresce quadraticamente (complexidade O(n¬≤)) com o tamanho do dataset <a href="#ref1">[1]</a>, ou mais precisamente, ¬†para a tarefa mais comum de uma √∫nica consulta de predi√ß√£o, a complexidade √© descrita como O(n‚ãÖd), frequentemente simplificada para O(n) quando a dimensionalidade √© tratada como constante <a href="#ref2">[2]</a>. Para o <b>MovieLens 25M</b>, com mais de 162 mil usu√°rios e 62 mil filmes, essa abordagem se torna invi√°vel pois tanto o n√∫mero de usu√°rios e a dimens√£o de filmes a ser analisadas √© alto. Adicionalmente para o segundo caso, calcular a similaridade para todos os pares de itens em um grande conjunto de dados √© computacionalmente invi√°vel <a href="#ref3">[3]</a>.
Al√©m desses problemas, ¬†fatores como alta dimensionalidade (conhecida com maldi√ß√£o da alta dimensionalidade), desempenho ineficiente para matrizes espar√ßas e alto consumo de mem√≥ria tornam essas abordagens pouco atrativivas <a href="#ref4">[4]</a>-<a href="#ref6">[6]</a>.

Em contraste, a t√©cnica de <b>Hashing Sens√≠vel √† Localidade (LSH) </b> se destaca como uma abordagem altamente eficiente para algoritmos de recomenda√ß√£o, superando as limita√ß√µes de m√©todos tradicionais, especialmente em contextos de grandes volumes de dados <a href="#ref7">[7]</a>,<a href="#ref8">[8]</a>. O principal objetido da LSH ¬†√© agrupar itens de entrada semelhantes, associando-os a um mesmo hash com alta probabilidade, tamb√©m conhecido como "buckets". Diferente das t√©cnicas de hash convencionais, o LSH maximiza as colis√µes de hash em vez de minimiz√°-las <a href="#ref9">[9]</a>. Isso permite acelerar a busca por vizinhos pr√≥ximos em conjuntos de dados de alta dimensionalidade, mitigando a "maldi√ß√£o da dimensionalidade" <a href="#ref10">[10]</a>.

Quando os dados s√£o representados como vetores em um espa√ßo de alta dimens√£o, a t√©cnica de LSH mais comum utiliza hiperplanos aleat√≥rios. O objetivo aqui √© agrupar vetores que apontam em dire√ß√µes semelhantes, o que √© medido pela <b>similaridade de cosseno</b>. ¬†O processo funciona da seguinte forma:

* **Cria√ß√£o de Hiperplanos**: V√°rios hiperplanos aleat√≥rios s√£o gerados no espa√ßo vetorial. Cada hiperplano divide o espa√ßo em duas metades.

* **Gera√ß√£o do Hash**: Para cada vetor de dados, um "hash" √© gerado com base em sua posi√ß√£o em rela√ß√£o a esses hiperplanos. Para cada hiperplano, se o vetor estiver de um lado, ele recebe um bit '1', e se estiver do outro lado, recebe um bit '0'.

* **C√≥digo de Hash**: Ao combinar os bits de todos os hiperplanos, cada vetor recebe um c√≥digo de hash bin√°rio (uma sequ√™ncia de 0s e 1s). Vetores que est√£o pr√≥ximos no espa√ßo angular (alta similaridade de cosseno) t√™m uma alta probabilidade de cair do mesmo lado de muitos dos hiperplanos aleat√≥rios, resultando em c√≥digos de hash id√™nticos ou muito semelhantes.

No contexto de LSH, esse c√≥digo de hash bin√°rio serve como a chave para o bucket. A cria√ß√£o desses buckets de candidatos √© a raz√£o fundamental pela qual o LSH consegue mitigar a "maldi√ß√£o da dimensionalidade". A pergunta crucial que surge dessa abordagem √©: qual √© o verdadeiro ganho de desempenho e quais s√£o os custos associados a essa aproxima√ß√£o?

Em contraste com uma busca por for√ßa bruta (k-NN), cujo custo computacional cresce de forma linear ou quadr√°tica com o volume de dados (O(nd) ou O(n¬≤)) e se torna rapidamente proibitivo, o LSH direciona a busca apenas para um pequeno subconjunto de itens promissores. Ao consultar apenas os candidatos que colidem no mesmo bucket, o tempo de busca √© drasticamente reduzido para uma complexidade sublinear, representando o seu principal ganho. Contudo, essa efici√™ncia n√£o √© gratuita e seu custo mais significativo reside na pr√≥pria aproxima√ß√£o. O LSH aceita a possibilidade de erros, que se manifestam como falsos negativos, onde um vizinho real √© perdido por n√£o colidir em nenhum bucket, e falsos positivos, onde itens n√£o similares colidem por acaso, exigindo verifica√ß√µes de dist√¢ncia desnecess√°rias que consomem tempo. A gest√£o desses erros constitui um segundo custo, o de engenharia, pois exige um ajuste fino dos par√¢metros do algoritmo ‚Äî como o n√∫mero de tabelas de hash (L) e de fun√ß√µes por tabela (k) ‚Äî para encontrar o balan√ßo ideal entre a precis√£o dos resultados e a velocidade da consulta. Por fim, h√° o custo inicial de pr√©-processamento e mem√≥ria, um investimento de tempo e recursos computacionais necess√°rio para construir e armazenar as tabelas de hash antes que qualquer busca possa ser realizada.

A proposta desenvolvida neste estudo √¢ncora-se na ideia simplista do k-NN e as vantagens da abordagem LSH. Para evitar essa busca exaustiva, o sistema utiliza LSH como um poderoso filtro inteligente na primeira etapa. Cada usu√°rio, representado por seu perfil de avalia√ß√µes de filmes, √© mapeado para buckets LSH, que funcionam como "vizinhan√ßas" de gostos, agrupando usu√°rios com perfis de avalia√ß√£o parecidos. Assim, quando √© necess√°rio encontrar os vizinhos mais pr√≥ximos de um usu√°rio, o sistema n√£o varre todo o banco de dados. Em vez disso, ele usa o LSH para filtrar rapidamente um conjunto reduzido de candidatos promissores ‚Äî aqueles que ca√≠ram nos mesmos buckets que o usu√°rio alvo. S√≥ ent√£o, dentro desse conjunto pr√©-filtrado e muito menor, √© aplicado o c√°lculo de similaridade cosseno (KNN) para selecionar os K vizinhos mais pr√≥ximos e, finalmente, gerar as recomenda√ß√µes.

Dessa forma, o sistema combina o melhor dos dois mundos: a velocidade da busca aproximada do LSH para identificar um bairro relevante de usu√°rios e a precis√£o da m√©trica de similaridade do KNN para fazer a escolha final dentro do bucket. Esta abordagem em duas etapas resolve diretamente a quest√£o da escalabilidade, permitindo que recomenda√ß√µes personalizadas sejam geradas de maneira eficiente, mesmo em um ecossistema com um n√∫mero massivo de usu√°rios e itens.

Ao gerar as recomen√ß√µes faz necess√°rio avaliar a qualidade das sugest√µes de filmes sugeridas pelo algoritmo. Em nossa abordagem de recomenda√ß√£o, cada filme candidato recebe um grau de prefer√™ncia calculado a partir das avalia√ß√µes de usu√°rios semelhantes, de modo que os vizinhos com perfis mais pr√≥ximos exercem maior influ√™ncia. Para isso, combinamos cada avalia√ß√£o com o grau de similaridade do usu√°rio que a fez e, em seguida, normalizamos pelo total de similaridade acumulada, garantindo que opini√µes mais alinhadas pesem mais no resultado final. Essa estimativa √© ent√£o convertida para uma escala percentual, refletindo o n√≠vel de confiabilidade da recomenda√ß√£o. Por fim, apresentamos ao usu√°rio apenas os t√≠tulos que ele ainda n√£o viu, ordenados pelo valor percentual, de modo a destacar primeiro as op√ß√µes com maior chance de agradar. </p>

<h2 id="datasets"> üìä Datasets</h2>
O conjunto de dados utilizados no sistema de recomenda√ß√£o √© o **MovieLens 25M**, dispon√≠vel na plataforma Kaggle [`ml-25m`](https://www.kaggle.com/datasets/patriciabrezeanu/movielens-full-25-million-recommendation-data). Ele cont√©m registros de classifica√ß√£o de filmes por estrelas, al√©m de marca√ß√µes com texto livre realizadas na plataforma oficial [MovieLens](http://movielens.org), um renomado servi√ßo de recomenda√ß√£o de filmes.

Este extenso conjunto de dados apresenta as seguintes caracter√≠sticas gerais:

-   **Total de avalia√ß√µes:** 25.000.095 classifica√ß√µes
-   **Total de marca√ß√µes (tags):** 1.093.360 tags aplicadas
-   **Quantidade de filmes:** 62.423 filmes inclu√≠dos
-   **Per√≠odo de coleta:** 9 de janeiro de 1995 a 21 de novembro de 2019
-   **Usu√°rios:** 162.541 usu√°rios selecionados aleatoriamente

Para alimentar o sistema de recomenda√ß√£o, os dados utilizados foram especificamente os arquivos `movies.csv` e `ratings.csv`.

Em rela√ß√£o aos usu√°rios e √† estrutura dos dados:
-   Todos os usu√°rios selecionados avaliaram pelo menos **20 filmes**.
-   Todos os arquivos do conjunto de dados s√£o formatados em `.csv`, contendo uma √∫nica linha de cabe√ßalho.
-   Colunas que cont√™m v√≠rgulas (`,`) s√£o escapadas utilizando **aspas duplas** (`"`).
-   Os arquivos s√£o codificados em **UTF-8**.

### Estrutura dos Arquivos Usados

#### `ratings.csv`
Este arquivo cont√©m todas as avalia√ß√µes dos usu√°rios. Cada linha, ap√≥s o cabe√ßalho, representa uma **avalia√ß√£o de um filme por um usu√°rio**, no seguinte formato:

```csv
userId,movieId,rating,timestamp
```

#### `movies.csv`
Este arquivo cont√©m informa√ß√µes sobre os filmes presentes no conjunto de dados MovieLens 25M. Cada linha, ap√≥s o cabe√ßalho, representa um filme e segue o seguinte formato:

```csv
movieId,title,genres
```

<h2 id="estrutura"> üß¨ Estrutura do Projeto</h2>

```text
üìÅ projeto/
‚îú‚îÄ‚îÄ üìÇ data/              # Arquivos de entrada/sa√≠da
‚îú‚îÄ‚îÄ üìÇ src/               # C√≥digos principais
‚îú‚îÄ‚îÄ üìÇ results/           # Resultados e gr√°ficos gerados
‚îú‚îÄ‚îÄ üìÇ utils/             # Fun√ß√µes auxiliares
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt
```

<h2 id="modelagem-e-implementacao"> üíª Modelagem e Implementa√ß√£o</h2>

A escolha do C++ para a implementa√ß√£o do sistema de recomenda√ß√£o de filmes foi motivada pela sua capacidade de oferecer controle de baixo n√≠vel e elevado desempenho computacional, caracter√≠sticas cruciais para processar eficazmente grandes volumes de dados. Esta robustez √© complementada pela utiliza√ß√£o estrat√©gica de estruturas de dados otimizadas da Standard Template Library (STL) e pela paraleliza√ß√£o intensiva via OpenMP, visando a maximiza√ß√£o da efici√™ncia e a escalabilidade do processamento, especialmente cr√≠tica para o manejo de datasets volumosos. A arquitetura adotada para o projeto √© intrinsecamente modular, concebida para promover a clareza, a manutenibilidade e a extensibilidade. Esta organiza√ß√£o l√≥gica compreende um pipeline integral que se estende desde o processamento inicial e a curadoria dos dados at√© a fase final de gera√ß√£o de recomenda√ß√µes e a rigorosa avalia√ß√£o do modelo. Para garantir uma execu√ß√£o sequencial e l√≥gica, esses componentes foram articulados em fases distintas, a saber:

* ‚öôÔ∏è **Fase 1:** <a href="#fase1-dados">Carregamento e Pr√©-processamento de Dados</a>
* üèóÔ∏è **Fase 2:** <a href="#fase2-modelo">Constru√ß√£o de Componentes do Modelo Central</a>
* ‚ö° **Fase 2.5:** <a href="#fase2_5-lsh">Constru√ß√£o do Modelo LSH</a>
* üí° **Fase 3:** <a href="#fase3-recomendacoes">Gera√ß√£o de Recomenda√ß√µes LSH</a>
* üìä **M√≥dulo de Avalia√ß√£o:** <a href="#modulo-avaliacao">Avalia√ß√£o do Modelo</a>

### Defini√ß√£o de Tipos de Dados

Para promover a clareza, a legibilidade e a manutenibilidade do c√≥digo-fonte, o projeto faz uso extensivo de **alias de tipos (type aliases)**. Essas defini√ß√µes, centralizadas no [arquivo `types.hpp`](src/types.hpp), padronizam as estruturas de dados complexas e conferem maior expressividade aos nomes das vari√°veis e par√¢metros, refletindo seu prop√≥sito dentro do algoritmo. O detalhamento de cada tipo ser√° apresentado contextualmente ao longo da descri√ß√£o das fases de implementa√ß√£o, no momento de sua primeira utiliza√ß√£o relevante.

<h3 id="fase1-dados">‚öôÔ∏è Fase 1: Carregamento e Pr√©-processamento de Dados</h3>

<p align="justify">
A primeira fase da execu√ß√£o do sistema consiste no carregamento e na prepara√ß√£o dos dados. Este processo √© fundamental para garantir a qualidade e a efici√™ncia das recomenda√ß√µes geradas. As etapas s√£o executadas na seguinte ordem:
</p>

<ol>
  <li>
    <p align="justify">
      <strong>Leitura dos Dados Brutos</strong>:
    </p>
    <ul>
      <li>O sistema inicia lendo o arquivo de avalia√ß√µes, localizado em <code>../dataset/ratings.csv</code> , utilizando a fun√ß√£o <code>readRatingsCSV</code>. Cada linha do CSV, contendo <code>userId</code>, <code>movieId</code> e <code>rating</code>, √© processada e armazenada em uma estrutura de dados <code>UserRatingsLog</code>.</li>
      <li>Paralelamente, os t√≠tulos dos filmes s√£o carregados a partir do arquivo <code>../dataset/movies.csv</code>, pela fun√ß√£o <code>readMovieTitles</code> , associando cada <code>movieId</code> ao seu respectivo t√≠tulo em uma estrutura <code>MovieTitlesMap</code>.</li>
    </ul>
  </li>
  <li>
    <p align="justify">
      <strong>Contagem e Filtragem de Entidades</strong>:
    </p>
    <ul>
      <li>Para otimizar a base de dados, √© realizada uma contagem do n√∫mero de avalia√ß√µes por usu√°rio e por filme atrav√©s da fun√ß√£o <code>countEntityRatings</code>.</li>
      <li>Em seguida, o sistema aplica um filtro para manter apenas entidades com um n√∫mero m√≠nimo de intera√ß√µes. De acordo com o arquivo de configura√ß√£o <code>config.hpp</code>, s√£o considerados v√°lidos os usu√°rios e filmes que possuem pelo menos <strong>5 avalia√ß√µes</strong> (<code>MIN_RATINGS_PER_ENTITY = 5</code>). Esta identifica√ß√£o √© feita pela fun√ß√£o <code>identifyValidEntities</code>.</li>
      <li>A fun√ß√£o <code>filterUserRatingsLog</code> √© ent√£o chamada para remover todos os usu√°rios que n√£o atendem ao crit√©rio m√≠nimo e, para os usu√°rios restantes, remove as avalia√ß√µes de filmes que tamb√©m n√£o atendem ao limiar.</li>
    </ul>
  </li>
  <li>
    <p align="justify">
      <strong>Gera√ß√£o dos Arquivos de Sa√≠da do Pr√©-processamento</strong>:
    </p>
    <ul>
      <li><strong>Arquivo de Dados Filtrado</strong>: O conjunto de dados j√° processado e filtrado √© salvo no arquivo <code>filtered_dataset.dat</code> , utilizando a fun√ß√£o <code>writeFilteredRatingsToFile</code>. O formato de sa√≠da segue o padr√£o <code>usuario_id item_id1:nota1 item_id2:nota2 ...</code>:.</li>
  </li>
</ol>

<h3 id="fase2-modelo">üèóÔ∏è Fase 2: Constru√ß√£o de Componentes do Modelo Central</h3>

A Fase 2 do processo de implementa√ß√£o concentra-se na transforma√ß√£o dos dados de avalia√ß√µes pr√©-processados em estruturas otimizadas, essenciais para os c√°lculos de similaridade subjacentes ao algoritmo de recomenda√ß√£o. Este conjunto de opera√ß√µes √© implementado no m√≥dulo `recommender_engine.cpp/.hpp`.

Os principais processos realizados nesta fase s√£o:

1.  **Mapeamento de Avalia√ß√µes para Matriz Esparsa de Usu√°rio-Item:**
    * Esta fun√ß√£o √© respons√°vel por converter o formato inicial de log de avalia√ß√µes, representado por `UserRatingsLog` (um `std::unordered_map` onde cada `UserID` √© mapeado a um `std::vector` de pares `(MovieID, Rating)`), em uma `UserItemMatrix`. A `UserItemMatrix` √© uma estrutura `std::unordered_map<int, std::unordered_map<int, float>>`, que, de forma qualitativa, age como uma representa√ß√£o esparsa da matriz de avalia√ß√µes. Sua escolha √© estrat√©gica para **otimiza√ß√£o de acesso**: ao aninhar `unordered_maps`, o sistema permite que, dado um `UserID` e um `MovieID`, a avalia√ß√£o correspondente seja acessada diretamente com complexidade m√©dia de tempo constante ($O(1)$). Isso √© fundamental para a efici√™ncia em opera√ß√µes futuras, como o c√°lculo do produto escalar na similaridade de cosseno, onde a busca por avalia√ß√µes espec√≠ficas √© frequente e a esparsidade dos dados evita a aloca√ß√£o desnecess√°ria de mem√≥ria para filmes n√£o avaliados.

2.  **Pr√©-c√°lculo e Armazenamento das Normas de Usu√°rios**
    * A `computeUserNorms` calcula a norma Euclidiana (L2) para o vetor de avalia√ß√µes de cada usu√°rio presente na rec√©m-constru√≠da `UserItemMatrix`. As normas s√£o ent√£o armazenadas na estrutura `UserNormsMap`, que √© um `std::unordered_map<int, float>`. O **foco principal na otimiza√ß√£o** aqui reside no **pr√©-c√°lculo e armazenamento dessas magnitudes**. A similaridade de cosseno, m√©trica central para determinar a semelhan√ßa entre usu√°rios, exige a divis√£o pelo produto das normas dos vetores comparados. Ao ter as normas j√° computadas e acess√≠veis em $O(1)$, o sistema evita a repeti√ß√£o de um c√°lculo de raiz quadrada e somas para cada par de usu√°rios durante as milh√µes de compara√ß√µes de similaridade que ocorrem nas fases de busca por vizinhos. Este processo √© adicionalmente **paralelizado utilizando OpenMP**, o que distribui a carga computacional de c√°lculo de normas entre m√∫ltiplos n√∫cleos de processamento, acelerando significativamente a prepara√ß√£o dos dados para a fase LSH em grandes datasets.

Ao final desta fase, o sistema possui a `UserItemMatrix` e a `UserNormsMap` totalmente constru√≠das, representando os perfis de usu√°rios em um formato otimizado para as opera√ß√µes de hashing sens√≠vel √† localidade e busca por vizinhos.

<h3 id="fase2_5-lsh">‚ö° Fase 2.5: Constru√ß√£o do Modelo LSH</h3>

<p align="justify">
Esta √© a fase central da otimiza√ß√£o, onde as estruturas de dados do <i>Locality-Sensitive Hashing</i> s√£o constru√≠das. O objetivo √© criar um √≠ndice que permita agrupar usu√°rios com perfis de avalia√ß√£o similares em "buckets" compartilhados, eliminando a necessidade de comparar cada usu√°rio com todos os outros.
</p>

<ol>
  <li>
    <p align="justify">
      <p align="justify">
  <strong>Mapeamento de Dimens√µes</strong>:
</p>
<ul>
  <li>
    Os <code>movieId</code>s originais, que s√£o esparsos e n√£o sequenciais, s√£o mapeados para um vetor de √≠ndices densos. Essa etapa √© crucial para criar uma representa√ß√£o vetorial consistente para cada usu√°rio. A estrutura <code>MovieIdToDenseIdxMap</code> funciona como um "dicion√°rio tradutor".
  </li>
  <li>
    Como o c√≥digo processa os <code>movieIds</code> √∫nicos em ordem crescente (por usar um <code>std::set</code>), a atribui√ß√£o dos √≠ndices densos √© previs√≠vel e est√°vel. Veja um exemplo simplificado:
  </li>
</ul>

| Original `movieId` (Esparso) | Novo `√≠ndice` (Denso) |
| :--------------------------- | :-------------------- |
| 1                            | 0                     |
| 8                            | 1                     |
| 780                          | 2                     |
| 59315                        | 3                     |
| ...e assim por diante        | ...                   |

<ul>
  <li>
    Com esse mapeamento, o perfil de avalia√ß√µes de qualquer usu√°rio pode ser convertido em um vetor de tamanho fixo (onde o tamanho √© o n√∫mero total de filmes √∫nicos). A posi√ß√£o (√≠ndice) no vetor corresponde diretamente ao "Novo <code>√≠ndice</code> (Denso)" do filme.
  </li>
  <li>
    <strong>Exemplo pr√°tico:</strong> Se um usu√°rio avaliou apenas os filmes <code>movieId=780</code> (nota 5.0) e <code>movieId=1</code> (nota 4.0), seu vetor de perfil seria:
    <br>
    <code>perfil_usuario = [ 4.0, 0.0, 5.0, 0.0, ... ]</code>
    <ul>
        <li>O valor <strong>4.0</strong> est√° no <strong>√≠ndice 0</strong> (pois <code>movieId=1</code> foi mapeado para 0).</li>
        <li>O valor <strong>5.0</strong> est√° no <strong>√≠ndice 2</strong> (pois <code>movieId=780</code> foi mapeado para 2).</li>
    </ul>
  </li>
  <li>
    √â este vetor denso que o algoritmo LSH utiliza para realizar os c√°lculos de produto escalar com os hiperplanos.
  </li>
</ul>
  </li>
  <li>
    <p align="justify">
      <strong>Gera√ß√£o dos Hiperplanos Aleat√≥rios</strong>:
    </p>
    <ul>
      <li>A fun√ß√£o <code>generateSingleHyperplaneSet</code> √© chamada em um la√ßo para gerar m√∫ltiplos conjuntos de hiperplanos aleat√≥rios. Cada conjunto, do tipo <code>HyperplaneSet</code>, corresponde a uma tabela de hash LSH.</li>
      <li>O n√∫mero de tabelas de hash (<code>NUM_LSH_TABLES = 10</code>) e o n√∫mero de hiperplanos por tabela (<code>NUM_HYPERPLANES_PER_TABLE = 16</code>) s√£o determinados pelas constantes no arquivo <code>config.hpp</code>.</li>
      <li>Cada hiperplano √© um vetor cujos componentes s√£o amostrados de uma distribui√ß√£o normal padr√£o (<code>std::normal_distribution</code>), garantindo a aleatoriedade necess√°ria para a t√©cnica.</li>
    </ul>
  </li>
  <li>
    <p align="justify">
      <strong>Constru√ß√£o das Tabelas de Hash (Buckets)</strong>:
    </p>
    <ul>
      <li>A fun√ß√£o <code>buildLSHTables</code> itera sobre cada usu√°rio da matriz e, para cada uma das tabelas de hash, calcula um valor de hash atrav√©s da fun√ß√£o <code>computeLSHHash</code>.</li>
      <li><code>computeLSHHash</code> projeta o vetor de avalia√ß√µes do usu√°rio em cada hiperplano (via produto escalar). O sinal do resultado (positivo ou negativo) determina o bit correspondente (1 ou 0) no hash final, que √© do tipo <code>LSHHashValue</code>.</li>
      <li>Usu√°rios com o mesmo hash s√£o inseridos no mesmo "bucket" (uma lista de <code>userId</code>s) dentro de uma <code>LSHBucketMap</code>. Este processo √© paralelizado com OpenMP (<code>#pragma omp parallel for</code>) para maior efici√™ncia na constru√ß√£o das tabelas.</li>
    </ul>
  </li>
</ol>

<h3 id="fase3-recomendacoes">üí° Fase 3: Gera√ß√£o de Recomenda√ß√µes LSH</h3>

<h3 id="modulo-avaliacao">üìä M√≥dulo de Avalia√ß√£o: Avalia√ß√£o do Modelo</h3>


<h2 id="autores"> üë• Autores</h2>

* [<img src="https://cdn.jsdelivr.net/npm/simple-icons@latest/icons/github.svg" width="24" alt="GitHub">](https://github.com/peixotoigor) Igor Peixoto
* [<img src="https://cdn.jsdelivr.net/npm/simple-icons@latest/icons/github.svg" width="24" alt="GitHub">](https://github.com/PeedroHG) Pedro Galv√£o
* [<img src="https://cdn.jsdelivr.net/npm/simple-icons@latest/icons/github.svg" width="24" alt="GitHub">](https://github.com/joaopaulocruzdefaria) Jo√£o Cruz
* [<img src="https://cdn.jsdelivr.net/npm/simple-icons@latest/icons/github.svg" width="24" alt="GitHub">](https://github.com/Lucas-Roseno) Lucas Roseno
* [<img src="https://cdn.jsdelivr.net/npm/simple-icons@latest/icons/github.svg" width="24" alt="GitHub">](https://github.com/LuizFernandosq) Luiz Santos

<details id="referencias">
  <summary><b>üìö Refer√™ncias</b></summary>
  <ol>
    <li id="ref1">ALMANSOORI, Mahmood KM; MESZAROS, Andras; TELEK, Miklos. Fast and memory-efficient approximate minimum spanning tree generation for large datasets. Arabian Journal for Science and Engineering, v. 50, n. 2, p. 1233-1246, 2025.</li>
    <li id="ref2">PANDIT, Gaurav; R√ñDER, Michael; NGONGA NGOMO, Axel-Cyrille. Evaluating Approximate Nearest Neighbour Search Systems on Knowledge Graph Embeddings. In: European Semantic Web Conference. Springer, Cham, 2025. p. 59-76.</li>
    <li id="ref3">YAMAMURA, Hugo Hiroshi. R ‚Äì E. 2025. Dispon√≠vel em: https://acervodigital.ufpr.br/xmlui/bitstream/handle/1884/93822/R%20-%20E%20-%20HUGO%20HIROSHI%20YAMAMURA.pdf?sequence=1&isAllowed=y. Acesso em: 2 jun. 2025.</li>
    <li id="ref4">ANASTASIU, David C.; KARYPIS, George. Fast parallel cosine k-nearest neighbor graph construction. In: 2016 6th Workshop on Irregular Applications: Architecture and Algorithms (IA3). IEEE, 2016. p. 50-53.</li>
    <li id="ref5">HYV√ñNEN, Ville et al. Fast k-nn search. arXiv preprint arXiv:1509.06957, 2015.</li>
    <li id="ref6">FU, Jiuzhou; ZHAO, Dongfang. MPAD: A New Dimension-Reduction Method for Preserving Nearest Neighbors in High-Dimensional Vector Search. arXiv preprint arXiv:2504.16335, 2025.</li>
    <li id="ref7">RABBANI, Tahseen; BORNSTEIN, Marco; HUANG, Furong. Large-scale distributed learning via private on-device lsh. Advances in Neural Information Processing Systems, v. 36, p. 16153-16171, 2023.</li>
    <li id="ref8">ZHANG, Kunpeng; FAN, Shaokun; WANG, Harry Jiannan. An efficient recommender system using locality sensitive hashing. 2018.</li>
    <li id="ref9">LESKOVEC, J.; RAJARAMAN, A.; ULLMAN, J. D. Mining of Massive Datasets, Cambridge University Press, Cambridge [em linha]. 2014.</li>
    <li id="ref10">INDYK, Piotr; MOTWANI, Rajeev. Approximate nearest neighbors: towards removing the curse of dimensionality. In: Proceedings of the thirtieth annual ACM symposium on Theory of computing. 1998. p. 604-613.</li>
  </ol>
</details>